{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/parkgeunyoung1/test/blob/master/(%EC%8B%A4%EC%8A%B5_%EB%AC%B8%EC%A0%9C)2_1_%ED%86%A0%ED%81%B0%ED%99%94%2C%EC%9E%84%EB%B2%A0%EB%94%A9_%EC%8B%A4%EC%8A%B5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1f4b6a34",
      "metadata": {
        "id": "1f4b6a34"
      },
      "source": [
        "### **Content License Agreement**\n",
        "\n",
        "<font color='red'><b>**WARNING**</b></font> : 본 자료는 삼성청년SW·AI아카데미의 컨텐츠 자산으로, 보안서약서에 의거하여 어떠한 사유로도 임의로 복사, 촬영, 녹음, 복제, 보관, 전송하거나 허가 받지 않은 저장매체를 이용한 보관, 제3자에게 누설, 공개 또는 사용하는 등의 무단 사용 및 불법 배포 시 법적 조치를 받을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "add5dacf",
      "metadata": {
        "id": "add5dacf"
      },
      "source": [
        "### **Objectives**\n",
        "\n",
        "1. 실습명: 토큰화/임베딩 실습\n",
        "2. 핵심 주제\n",
        "    1) tokenizer를 이용하여 단어들을 토큰으로 변환하는 과정을 이해\n",
        "    2) 토큰화된 토큰들을 임베딩 벡터로 변환하는 과정을 이해\n",
        "    3) RNN부터 트랜스포머까지 모델의 발전사를 직접 체험하고 각 요소 기술의 역할을 이해\n",
        "3. 학습 목표\n",
        "    1) 토크나이저가 무엇이고 토큰화가 무엇인지에 대해서 설명할 수 있다.\n",
        "    2) 토큰화를 왜 하는지에 대해서 설명할 수 있다.\n",
        "    3) 토큰화된 토큰들을 임베딩 벡터로 변환하는 과정을 이해할 수 있다.\n",
        "    4) 임베딩 벡터를 이용하여 어떤 식으로 활용할 수 있는지 설명할 수 있다.\n",
        "    5) 다양한 모델의 발전사에 대해 직접 체험하고 각 아키텍쳐가 가지는 특징을 설명할 수 있다.\n",
        "\n",
        "4. 학습 개념\n",
        "    1) 토큰화:\n",
        "    2) 임베딩 벡터:\n",
        "    3) 인코더/디코더:\n",
        "  \n",
        "5. 학습 방향\n",
        "    - 실습은 아래 내용들을 직접 체험하고 각 아키텍쳐가 가지는 특징을 이해하는 것이 목표입니다.\n",
        "      - 토큰화\n",
        "      - 임베딩\n",
        "      - RNN\n",
        "      - LSTM\n",
        "      - 어텐션 메커니즘\n",
        "      - 인코더\n",
        "      - 디코더\n",
        "    - 실습 코드는 조교가 직접 구현한 코드를 참고하며 학습합니다.\n",
        "    - 자연스럽게 코드를 구현하면서 아키텍쳐의 발전사를 체험합니다.\n",
        "\n",
        "6. 데이터셋 개요 및 저작권 정보\n",
        "    - 데이터셋 명 : NSMC(Naver Sentiment Movie Corpus)\n",
        "    - 데이터셋 개요 : 네이버 영화 감정분석 데이터셋\n",
        "    - 데이터셋 저작권 : CC0 1.0"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c26eeb4b",
      "metadata": {
        "id": "c26eeb4b"
      },
      "source": [
        "### **Prerequisites**\n",
        "```\n",
        "numpy==2.0.2\n",
        "pandas==2.2.2\n",
        "tokenizers==0.21.4\n",
        "transformers==4.55.2\n",
        "torch==2.8.0+cu126\n",
        "```\n",
        "\n",
        "- 만약, 기본 코랩과 버전이 다르다면 아래 명령어를 복사해서 실행시켜주세요.\n",
        "```\n",
        "%pip install numpy==2.0.2 pandas==2.2.2 tokenizers==0.21.4 transformers==4.55.2 torch==2.8.0+cu126 --index-url https://download.pytorch.org/whl\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "id": "b1260a59",
      "metadata": {
        "id": "b1260a59"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from typing import (\n",
        "    Generic,\n",
        "    Tuple,\n",
        "    TypeVar,\n",
        "    List,\n",
        "    Union,\n",
        "    get_args\n",
        ")\n",
        "# 시드 설정\n",
        "np.random.seed(1234)\n",
        "torch.manual_seed(1234)\n",
        "torch.cuda.manual_seed(1234)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "Batch = TypeVar(\"Batch\", bound=int)\n",
        "Token = TypeVar(\"Token\", bound=int)\n",
        "Sequence = TypeVar(\"Sequence\", bound=int)\n",
        "Layers = TypeVar(\"Layers\", bound=int)\n",
        "HiddenStates = TypeVar(\"HiddenStates\", bound=int)\n",
        "VocabSize = TypeVar(\"VocabSize\", bound=int)\n",
        "EmbeddingSize = TypeVar(\"EmbeddingSize\", bound=int)\n",
        "MaxLength = TypeVar(\"MaxLength\", bound=int)\n",
        "\n",
        "_1D = TypeVar(\"_1D\")\n",
        "_2D = TypeVar(\"_2D\")\n",
        "_3D = TypeVar(\"_3D\")\n",
        "\n",
        "def _label_str(self) -> str:\n",
        "    \"\"\"인스턴스의 제네릭 라벨 이름을 예쁘게 표시 (e.g., [Sequence])\"\"\"\n",
        "    oc = getattr(self, \"__orig_class__\", None)\n",
        "    if oc is None:\n",
        "        return \"[]\"\n",
        "    args = get_args(oc)\n",
        "    names = [getattr(a, \"__name__\", str(a)) for a in args]\n",
        "    return \"[\" + \", \".join(names) + \"]\"\n",
        "\n",
        "\n",
        "class Tensor1D(Generic[_1D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 1, ValueError(\"Tensor must be 1-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.s: _1D = tensor.size(0)  # sequence length\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.s}))\"\n",
        "\n",
        "class Tensor2D(Generic[_1D, _2D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 2, ValueError(\"Tensor must be 2-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}))\"\n",
        "\n",
        "\n",
        "class Tensor3D(Generic[_1D, _2D, _3D]):\n",
        "    def __init__(self, tensor: torch.Tensor):\n",
        "        assert tensor.dim() == 3, ValueError(\"Tensor must be 3-dimensional\")\n",
        "        self.tensor = tensor\n",
        "        self.b: _1D = tensor.size(0)  # batch size\n",
        "        self.s: _2D = tensor.size(1)  # sequence length\n",
        "        self.h: _3D = tensor.size(2)  # hidden state size\n",
        "        assert self.b == tensor.size(0), ValueError(\n",
        "            f\"Expected batch {self.b}, but got {tensor.size(0)}\"\n",
        "        )\n",
        "        assert self.s == tensor.size(1), ValueError(\n",
        "            f\"Expected Sequence {self.s}, but got {tensor.size(1)}\"\n",
        "        )\n",
        "        assert self.h == tensor.size(2), ValueError(\n",
        "            f\"Expected Hidden State {self.h}, but got {tensor.size(2)}\"\n",
        "        )\n",
        "\n",
        "    def size(self) -> Tuple[int, int]:\n",
        "        return self.tensor.size()\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return f\"Tensor(shape=({self.b}, {self.s}, {self.h}))\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d55eb901",
      "metadata": {
        "id": "d55eb901"
      },
      "source": [
        "# 1. 토크나이저 / 워드 임베딩\n",
        "\n",
        "- 학습 목표\n",
        "  1. 토크나이저를 학습할 수 있다.\n",
        "  2. 토크나이저를 사용하여 텍스트를 토큰 ID 시퀀스로 변환하는 방법을 이해하고 구현할 수 있ㅏ.\n",
        "- 학습 개념\n",
        "  1. 토크나이저\n",
        "  2. 토큰화\n",
        "  3. 임베딩\n",
        "- 진행하는 실습 요약\n",
        "  1. 제공된 말뭉치로 WordPiece 토크나이저를 훈련시키는 코드 한 줄을 완성\n",
        "  2. 훈련된 토크나이저를 사용해 특정 문장을 토큰 ID 시퀀스로 변환하는 코드\n",
        "  3. nn.Embedding 레이어(혹은 간단한 dict lookup)를 사용하여 주어진 토큰 ID에 해당하는 임베딩 벡터를 조회하는 코드"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c42fdfec",
      "metadata": {
        "id": "c42fdfec"
      },
      "source": [
        "### 1.1. Tokenizer 학습\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 토크나이저 학습</b><br>\n",
        "언어 모델에서 토크나이저는 텍스트를 토큰으로 변환하는 역할을 합니다. 토크나이저를 학습하는 방법에 대해 알아봅니다.\n",
        "</blockquote>\n",
        "\n",
        "토크나이저를 학습하기 위해서는 다음 두가지가 필요합니다.\n",
        "1. 토크나이저 객체(클래스)\n",
        "2. 학습 데이터\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9cc62bac",
      "metadata": {
        "id": "9cc62bac"
      },
      "source": [
        "그러면 우선 학습 데이터를 준비해보겠습니다.\n",
        "\n",
        "학습할 텍스트 데이터가 들어있는 파일을 준비합니다.\n",
        "\n",
        "여기서는 NSMC(Naver Sentiment Movie Corpus) 데이터셋을 사용하겠습니다.\n",
        "\n",
        "아래 명령어를 실행하여 데이터셋을 다운로드 받습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "id": "97b7effd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97b7effd",
        "outputId": "6e12901d-6797-4b25-f7c1-a65410b1f1b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-16 07:14:46--  https://github.com/e9t/nsmc/raw/master/ratings.txt\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt [following]\n",
            "--2025-10-16 07:14:46--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 19515078 (19M) [text/plain]\n",
            "Saving to: ‘ratings.txt.3’\n",
            "\n",
            "ratings.txt.3       100%[===================>]  18.61M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-10-16 07:14:46 (139 MB/s) - ‘ratings.txt.3’ saved [19515078/19515078]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/e9t/nsmc/raw/master/ratings.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "facaabde",
      "metadata": {
        "id": "facaabde"
      },
      "source": [
        "데이터셋을 확인해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "id": "dd94219a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "id": "dd94219a",
        "outputId": "46b3e916-e014-4d00-8ee8-8c34862b3643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "학습에 필요한 파일이 존재합니다! ratings.txt\n",
            "리뷰 갯수 : 199992\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id                                           document  label\n",
              "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
              "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
              "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
              "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
              "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8795a1ae-c63c-4042-957d-b85ff5920e1b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>document</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>8112052</td>\n",
              "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8132799</td>\n",
              "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4655635</td>\n",
              "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9251303</td>\n",
              "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10067386</td>\n",
              "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8795a1ae-c63c-4042-957d-b85ff5920e1b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8795a1ae-c63c-4042-957d-b85ff5920e1b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8795a1ae-c63c-4042-957d-b85ff5920e1b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ef537b7f-6b8e-40d9-9300-db5745f4fa95\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef537b7f-6b8e-40d9-9300-db5745f4fa95')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ef537b7f-6b8e-40d9-9300-db5745f4fa95 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "file_list = os.listdir()\n",
        "for file in file_list:\n",
        "    if \"ratings.txt\" == file:\n",
        "        print('학습에 필요한 파일이 존재합니다!', file)\n",
        "        df = pd.read_table( (os.getcwd() + '/' + file), encoding='utf-8') # 데이터 프레임으로 보기 편하게 바꿔줍시다!\n",
        "        df = df.dropna(how = 'any') # 널값을 없애줍니다!\n",
        "        print('리뷰 갯수 :', len(df))\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed3146be",
      "metadata": {
        "id": "ed3146be"
      },
      "source": [
        "텍스트 데이터가 있는 'document'열만을 가져오고\n",
        "\n",
        "해당 데이터를 txt 파일로 저장합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "id": "c0224daf",
      "metadata": {
        "id": "c0224daf"
      },
      "outputs": [],
      "source": [
        "with open((os.getcwd() + '/' + 'naver_review.txt'), 'w', encoding='utf8') as f:\n",
        "  lines = df[\"document\"].dropna().astype(str).tolist()\n",
        "  f.write(\"\\n\".join(lines))\n",
        "    # TODO: document 열만 가져와서 저장하는 코드를 구현합니다.\n",
        "    # FIXME"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "252458b8",
      "metadata": {
        "id": "252458b8"
      },
      "source": [
        "학습이 되어 있지 않은 빈 tokenizer를 생성합니다.\n",
        "\n",
        "여기서는 BertWordPieceTokenizer를 불러옵니다.\n",
        "\n",
        "##### 파라미터:\n",
        "- `strip_accents` : 입력 텍스트의 악센트(액센트)를 제거할지 여부를 결정하는 옵션입니다. 한국어를 학습할때에는 `False`로 설정합니다.\n",
        "- `lowercase` : 영어를 모두 소문자로 바꿉니다. `False`로 설정하면 영어를 대문자로 유지합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "id": "9d919be5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d919be5",
        "outputId": "04d68172-d43b-4583-d1f6-31c968a1bfa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Tokenizer(vocabulary_size=0, model=BertWordPiece, unk_token=[UNK], sep_token=[SEP], cls_token=[CLS], pad_token=[PAD], mask_token=[MASK], clean_text=True, handle_chinese_chars=True, strip_accents=False, lowercase=False, wordpieces_prefix=##)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "from tokenizers import BertWordPieceTokenizer\n",
        "\n",
        "# 빈 tokenizer 생성 : vocabulary_size = 0 인 것을 확인하실 수 있습니다.\n",
        "tokenizer = BertWordPieceTokenizer(\n",
        "    lowercase=False,\n",
        "    strip_accents=False,\n",
        ")\n",
        "tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a4e500b",
      "metadata": {
        "id": "3a4e500b"
      },
      "source": [
        "아래 코드를 실행하여 토크나이저를 학습합니다.\n",
        "#### 파라미터 설명:\n",
        "- `data_file` : 데이터 경로를 지정해줍니다. list 형태로 여러개의 파일을 지정해줄수도 있습니다.\n",
        "- `vocab_size (default: 30000)` : 단어사전 크기를 지정할 수 있습니다. 어떠한 값이 가장 좋다는 것은 없지만, 값이 클수록 많은 단어의 의미를 담을 수 있습니다.\n",
        "- `initial_alphabet` : 꼭 포함됐으면 하는 initial alphabet을 학습 전에 추가해줍니다.\n",
        "    - initial은 학습하기 이전에 미리 단어를 vocab에 넣는 것을 의미합니다.\n",
        "    - special token들도 initial에 vocab에 추가됩니다.\n",
        "- `limit_alphabet (default: 1000)` : initial tokens의 갯수를 제한합니다.\n",
        "- `min_frequency (default: 2)` : 최소 빈도수를 의미합니다. 만약 어떤 단어가 1번 나오면 vocab에 추가하지 않습니다.\n",
        "- `special_tokens` : 특수 토큰을 넣을 수 있습니다.. BERT에는 다음과 같은 토큰이 들어가야 합니다.\n",
        "    - `[PAD]` : 패딩을 위한 토큰\n",
        "    - `[UNK]` : OOV 단어를 위한 토큰\n",
        "    - `[CLS]` : 문장의 시작을 알리고 분류 문제에 사용되는 토큰\n",
        "    - `[SEP]` : 문장 사이사이를 구별해주는 토큰\n",
        "    - `[MASK]` : MLM 태스크를 위한 마스크 토큰\n",
        "- `wordpiece_prefix(default: '##')` : sub-word라는 것을 알려주는 표시입니다.\n",
        "    - BERT는 기본적으로 '##'을 씁니다.\n",
        "    - 예를 들어, `SS, ##AF, ##Y` 처럼 sub-word를 구분하기 위해 '##'을 사용합니다.\n",
        "- `show_progress` : 학습 과정을 보여줍니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "id": "82aa578c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "82aa578c",
        "outputId": "36d95657-db46-4b19-ecee-37e68ba97c0a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocab size :  30000\n",
            "['[PAD]', '[UNK]', '[CLS]', '[SEP]', '[MASK]', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/']\n"
          ]
        }
      ],
      "source": [
        "data_file = 'naver_review.txt'\n",
        "vocab_size = 30000\n",
        "min_frequency = 2\n",
        "initial_alphabet = []\n",
        "limit_alphabet = 6000\n",
        "special_tokens = [\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"]\n",
        "wordpieces_prefix = \"##\"\n",
        "show_progress=True\n",
        "\n",
        "tokenizer.train(\n",
        "    files = data_file,\n",
        "    vocab_size = vocab_size,\n",
        "    min_frequency = min_frequency,\n",
        "    initial_alphabet = initial_alphabet,\n",
        "    limit_alphabet = limit_alphabet,\n",
        "    special_tokens = special_tokens,\n",
        "    wordpieces_prefix = wordpieces_prefix,\n",
        "    show_progress = True,\n",
        ")\n",
        "\n",
        "vocab = tokenizer.get_vocab()\n",
        "print(\"vocab size : \", len(vocab))\n",
        "print(sorted(vocab, key=lambda x: vocab[x])[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83244f41",
      "metadata": {
        "id": "83244f41"
      },
      "source": [
        "### 1.2. 토크나이저를 이용한 토큰 ID 시퀀스 반환\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 토크나이저를 이용한 토큰 ID 시퀀스 반환</b><br>\n",
        "모델이 토큰을 이해하기 위해서는 정수값으로 반환하는 과정이 필요합니다. 토크나이저를 이용하여 텍스트 토큰을 ID 시퀀스로 변환합니다.\n",
        "</blockquote>\n",
        "\n",
        "아래 코드를 실행하여 토크나이저를 이용하여 텍스트 토큰을 ID 시퀀스로 변환합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "id": "a26d8b6b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a26d8b6b",
        "outputId": "47032972-76be-442c-f840-4b7ec8990a8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🌱토큰화 결과 : ['I', \"'\", 'm', 'a', 'st', '##ud', '##ent', 'of', 'S', '##S', '##A', '##F', '##Y', '!']\n",
            "🌱정수 인코딩 : [45, 11, 81, 69, 15444, 24900, 16072, 10280, 55, 3453, 3800, 3464, 4875, 5]\n",
            "🌈디코딩 : I ' m a student of SSAFY!\n"
          ]
        }
      ],
      "source": [
        "text = \"I'm a student of SSAFY!\"\n",
        "\n",
        "encoded = tokenizer.encode(text)\n",
        "print('🌱토큰화 결과 :',encoded.tokens)\n",
        "print('🌱정수 인코딩 :',encoded.ids)\n",
        "print('🌈디코딩 :',tokenizer.decode(encoded.ids))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "884cec1b",
      "metadata": {
        "id": "884cec1b"
      },
      "source": [
        "<blockquote>\n",
        "<b>🧠 토크나이저를 이용한 모델 입력 만들기</b><br>\n",
        "그렇다면 모델의 입력으로 넣기 위해서는 어떤 방식으로 토크나이징을 해야 할까요?\n",
        "</blockquote>\n",
        "\n",
        "위에 대한 답변은 앞으로 실습 코드를 진행하면서 나오기 때문에 이 점을 잊지 말고 계속 따라가시기 바랍니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a906dbd",
      "metadata": {
        "id": "7a906dbd"
      },
      "source": [
        "### 1.3. 임베딩 벡터\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 토큰 ID에 따라 어떤 방식으로 벡터화가 될까요?</b><br>\n",
        "토큰 ID에 해당하는 임베딩 벡터를 확인해보겠습니다.\n",
        "</blockquote>\n",
        "\n",
        "아래 코드를 실행하여 특정 토큰 ID에 따른 임베딩 벡터를 확인해보겠습니다.\n",
        "\n",
        "임베딩 벡터는 torch의 nn.Embedding 모듈을 사용하여 생성됩니다. 해당 임베딩 벡터는 모두 임의의 값으로 초기화됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "id": "db1e9b06",
      "metadata": {
        "id": "db1e9b06"
      },
      "outputs": [],
      "source": [
        "\n",
        "vocab_size = 10000      # 임베딩할 “토큰 개수”\n",
        "embed_dim  = 128        # 각 토큰 벡터 차원\n",
        "\n",
        "embedding_vector = nn.Embedding(num_embeddings=vocab_size, embedding_dim=embed_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e6473c",
      "metadata": {
        "id": "e7e6473c"
      },
      "source": [
        "임베딩 벡터를 초기화하려고 하니 다음 두가지 파라미터를 반드시 넣으라고 합니다.\n",
        "\n",
        "1. `num_embeddings`: 임베딩 사전의 크기 (size of the dictionary of embeddings)\n",
        "2. `embedding_dim`: 각 임베딩 벡터의 차원 (the size of each embedding vector)\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 num_embeddings </b><br>\n",
        "임베딩 사전의 크기는 무슨 의미일까요?\n",
        "</blockquote>\n",
        "\n",
        "여기서 `num_embeddings`는 고유한 토큰(단어, 문자 등)의 총 개수를 의미합니다. 즉, 어떤 `인덱스 → 벡터` 매핑 테이블을 만들 건데, 그 테이블에 몇 개의 항목이 들어가야 하는지를 정의하는 값입니다. tokenizer를 만들때 `vocab_size`와 동일한 값을 의미합니다.\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 embedding_dim </b><br>\n",
        "각 임베딩 벡터의 차원은 무슨 의미일까요?\n",
        "</blockquote>\n",
        "\n",
        "`embedding_dim`은 각 단어(또는 토큰)가 표현되는 벡터의 길이입니다. 즉, 하나의 단어를 어떤 숫자 벡터로 나타낼 때 그 벡터가 몇 차원인지 정하는 값입니다. 보통의 embedding은 `768`, `1024` 등 2의 제곱수 차원을 사용합니다. (\"어떤 값이 정답이다\" 하는 값이 있는 건 아닙니다.)\n",
        "\n",
        "여기서는 vocab_size와 embedding_dim을 768로 정의해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "id": "d9723eee",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d9723eee",
        "outputId": "885931b1-20a8-4bf0-c56e-32141ed55909"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ],
      "source": [
        "embedding_vector: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "embedding_vector.weight.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98a9214e",
      "metadata": {
        "id": "98a9214e"
      },
      "source": [
        "그러면 특정 토큰의 임베딩 벡터를 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "id": "8b4c3059",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8b4c3059",
        "outputId": "20cc2a17-5d6d-49fe-8d61-040c92b093e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token_id: 45\n",
            "input_id 차원: torch.Size([1])\n",
            "vector 차원: torch.Size([1, 768])\n",
            "vector: tensor([[-2.1132e-01,  3.6977e-01,  6.3180e-01,  1.2101e+00, -7.7923e-01,\n",
            "          2.7557e-01,  5.8255e-01,  3.3518e-01, -8.2951e-01, -1.7030e-01,\n",
            "          1.0375e-01,  2.6100e-01, -1.6981e+00, -6.1456e-01, -2.0615e-01,\n",
            "          7.1249e-01, -8.1707e-01,  6.4621e-01, -7.5907e-01,  9.9107e-01,\n",
            "          4.3536e-01, -5.6147e-02, -2.0681e+00,  1.8742e-01, -1.0573e+00,\n",
            "          2.2975e+00,  1.0601e+00,  1.9098e+00,  3.2311e-01, -1.0468e+00,\n",
            "          2.9685e-01, -4.5924e-01,  1.3630e+00, -1.0243e+00,  5.7569e-01,\n",
            "         -3.2585e-01, -4.0792e-01, -1.1404e+00,  2.3601e+00, -1.0337e+00,\n",
            "          9.6000e-01, -1.3510e+00,  1.7715e-01,  1.3491e+00, -5.1164e-01,\n",
            "          1.2058e-01, -1.2881e+00, -2.9942e-01,  8.1552e-01, -4.2328e-01,\n",
            "         -6.0015e-02,  1.2573e+00,  2.6217e-01, -1.3070e+00, -2.1146e-01,\n",
            "          1.0917e+00,  1.1258e+00,  1.9423e-01,  7.1714e-01, -1.3425e-01,\n",
            "          9.2573e-01,  6.3255e-01, -6.2904e-01,  7.5810e-01, -3.7266e-01,\n",
            "         -1.0914e+00, -7.4840e-01,  9.8230e-01, -2.2607e-01, -7.1767e-01,\n",
            "         -1.0490e+00, -8.1975e-01, -7.5777e-01,  1.0793e+00, -7.7021e-01,\n",
            "          2.6841e-01,  3.7572e-01,  1.0942e+00, -7.5246e-01, -2.1968e-01,\n",
            "         -3.8623e-01, -6.6925e-01,  3.9125e-01, -1.5615e+00,  1.4401e+00,\n",
            "         -2.5111e-01, -1.4013e-01,  5.2830e-01, -4.9113e-02,  2.1712e+00,\n",
            "          6.5125e-01,  5.6326e-01,  2.6925e-01,  5.2043e-01,  1.0864e+00,\n",
            "          2.0283e+00,  4.1540e-01, -1.4883e-01,  6.1625e-01, -9.7784e-01,\n",
            "         -5.2509e-01, -4.5479e-01, -9.5498e-01,  2.8062e-01,  6.1122e-01,\n",
            "          1.2823e+00, -1.9910e+00, -5.1676e-01,  5.1677e-01, -7.2378e-01,\n",
            "          8.4585e-02, -1.1694e+00,  1.2543e+00,  1.7942e+00,  2.4473e+00,\n",
            "          1.6454e-01, -6.1057e-01, -4.0422e-01,  2.0058e-01,  5.2142e-01,\n",
            "         -1.1192e-01, -4.0946e-01,  1.4258e+00,  1.9619e-01, -1.7293e+00,\n",
            "         -1.2233e+00,  6.7901e-01,  1.1151e+00,  8.1004e-01, -1.7766e+00,\n",
            "         -3.3510e-01,  1.3980e+00, -6.6130e-01,  1.2648e+00, -8.3139e-01,\n",
            "          1.2478e+00,  1.0836e+00,  5.4575e-01,  1.1013e+00, -6.9656e-01,\n",
            "          1.3444e+00, -1.0011e-02,  2.6890e-02, -1.4339e+00,  5.1961e-01,\n",
            "         -1.0495e+00,  1.2196e+00,  4.3340e-01,  1.1600e+00, -6.1691e-02,\n",
            "         -3.9251e-01, -7.6294e-02,  1.2861e+00,  3.2386e-02, -9.0241e-01,\n",
            "         -1.0667e+00,  3.7480e-01, -1.4914e-01,  1.1107e+00, -1.4925e+00,\n",
            "          9.9836e-01,  1.5988e-01, -6.3621e-01, -7.5347e-02,  1.5048e+00,\n",
            "         -1.3975e+00,  8.3081e-01, -9.8935e-02,  1.9911e+00,  1.0013e+00,\n",
            "          1.9215e-01, -2.3608e+00,  6.7198e-01, -8.5175e-01, -2.4034e-01,\n",
            "         -1.4307e+00, -1.0567e-01,  2.3460e-01, -4.3138e-01,  1.2186e+00,\n",
            "         -2.4234e-01,  1.6085e+00,  2.5328e-01, -1.1598e+00,  3.6062e-01,\n",
            "          2.1511e+00,  3.7851e-01, -6.4021e-01,  1.2204e+00, -1.6437e-01,\n",
            "         -9.9551e-01,  1.9795e+00, -1.6811e-01,  1.7492e+00, -4.4274e-01,\n",
            "         -8.7018e-01,  1.3006e+00,  3.9902e-01, -1.0828e+00, -5.3733e-01,\n",
            "         -9.6189e-02,  7.1595e-01,  5.5730e-02, -4.0582e-02,  2.5803e-01,\n",
            "         -3.9467e-01,  4.8328e-01, -1.6557e+00, -3.3689e-01,  4.2717e-01,\n",
            "          5.6250e-01,  7.5724e-02,  6.3567e-01, -3.3038e-01,  2.1976e-01,\n",
            "         -6.3561e-01, -7.3826e-01,  5.8449e-01, -3.3387e-01, -7.2061e-01,\n",
            "          1.2930e+00, -2.9053e+00,  1.2623e-01,  8.5748e-01, -2.0780e-01,\n",
            "         -1.6615e-02,  7.7928e-01,  5.0900e-01, -1.7595e+00, -2.5001e+00,\n",
            "         -1.4395e+00, -5.2194e-01, -2.0006e-01, -1.0805e+00, -5.8413e-02,\n",
            "         -1.7004e+00,  3.3697e-01,  3.1340e-01, -2.8206e-01,  7.8615e-01,\n",
            "          8.8682e-01,  1.2363e-01,  2.0136e+00,  2.3990e-01,  2.1928e-01,\n",
            "          1.7092e+00, -4.2735e-02, -5.8492e-01,  1.2387e+00,  1.1880e+00,\n",
            "         -2.9430e-01,  5.2909e-01, -3.2012e-01,  1.3337e+00,  7.4047e-01,\n",
            "         -2.0622e-01, -5.8941e-01, -2.3154e+00, -2.1398e-01, -1.7404e-01,\n",
            "          9.1216e-01, -1.3537e+00, -2.7619e+00, -2.6529e+00, -1.0789e+00,\n",
            "         -9.4244e-02,  2.2426e+00, -8.7022e-01,  1.4220e+00,  5.2569e-01,\n",
            "         -9.7460e-01,  4.7505e-01, -1.3682e+00,  7.9233e-01, -6.7198e-01,\n",
            "          1.4369e+00, -8.7361e-01,  4.4661e-01, -1.3557e+00,  5.9053e-01,\n",
            "         -1.1399e-01, -1.3458e-02, -1.6067e+00,  1.2235e+00, -3.7891e-02,\n",
            "         -8.6308e-01, -6.2468e-01,  1.6420e+00, -1.3167e+00,  7.2236e-01,\n",
            "          9.0983e-03,  4.4466e-01, -3.2208e-01, -1.3385e+00,  9.8775e-01,\n",
            "          9.0123e-01, -1.6198e+00,  2.2750e+00,  5.8922e-02, -4.9175e-01,\n",
            "          4.4312e-01, -1.8437e-01,  6.8838e-01, -1.7804e-01,  8.7199e-01,\n",
            "         -4.3649e-01, -1.3835e+00, -2.8255e-01, -7.2560e-01, -5.7069e-01,\n",
            "         -4.4419e-01,  9.0306e-01, -1.8477e-01, -2.4701e+00,  1.2836e-01,\n",
            "          1.9577e-01,  5.6776e-01,  8.1798e-01,  1.1210e+00,  2.7287e-01,\n",
            "         -2.4372e+00, -3.4780e-01, -5.8521e-01, -9.5733e-01, -1.3848e-01,\n",
            "         -8.2571e-01,  6.9897e-01, -2.0867e-01, -7.0476e-01, -9.0684e-01,\n",
            "          1.1170e+00, -2.5298e+00,  1.2892e+00, -2.4572e-01, -8.9438e-01,\n",
            "          1.1736e+00,  3.3795e-01,  7.2146e-01, -5.6528e-01, -1.6687e+00,\n",
            "         -5.6319e-01,  2.3394e-01,  6.1649e-01,  1.3442e+00,  5.0014e-01,\n",
            "          4.4585e-02,  1.1713e+00,  1.6523e+00, -3.5352e-02, -2.8076e-01,\n",
            "          1.0294e+00, -1.5892e+00, -2.5123e-01,  7.8768e-01,  1.4249e+00,\n",
            "         -7.9267e-01, -5.2228e-01, -7.8770e-01,  1.1512e+00, -4.2698e-01,\n",
            "          4.1924e-01, -5.5275e-01,  1.5538e+00, -7.1781e-01,  2.9349e-01,\n",
            "         -8.5417e-01,  6.0394e-01, -1.2225e+00,  4.9846e-01,  9.5649e-01,\n",
            "         -7.3035e-01,  4.3292e-01,  1.0373e+00,  2.3205e-01, -1.4827e-01,\n",
            "         -1.4027e+00, -5.9087e-01, -3.1384e-01,  1.7218e-02,  1.1411e+00,\n",
            "         -1.1624e+00,  1.9674e-01, -4.9704e-01,  2.1326e+00,  6.7000e-02,\n",
            "          4.3385e-01,  9.7348e-01, -8.4240e-01,  8.1496e-01,  2.3624e-01,\n",
            "         -3.4299e-01,  6.1457e-02, -1.0237e-01,  7.3612e-02,  3.7186e+00,\n",
            "          9.3175e-01, -9.3837e-02, -4.4028e-01, -2.2301e+00, -2.6994e-01,\n",
            "         -4.3337e-01,  6.5334e-01,  3.6469e-01,  7.9718e-01, -4.2835e-01,\n",
            "          5.3323e-01, -3.2967e-01,  6.1483e-02, -2.3519e-01,  7.1902e-01,\n",
            "         -8.9494e-01,  6.2673e-01, -6.6679e-02,  2.8325e+00, -4.2368e-01,\n",
            "         -5.8553e-01, -1.1980e+00,  8.5116e-01, -1.3988e+00,  3.4832e-01,\n",
            "         -7.0979e-01,  7.0457e-01, -1.4851e+00,  1.0919e+00, -1.1630e+00,\n",
            "          1.0739e-01, -5.5793e-01, -6.0908e-01,  1.4876e+00,  8.6164e-01,\n",
            "          1.2856e+00, -6.0217e-01, -1.3625e+00,  5.5301e-01,  7.8624e-01,\n",
            "         -8.5770e-01, -1.6964e+00, -6.6845e-01,  9.6821e-01, -1.8497e-01,\n",
            "          4.1605e-01,  4.1115e-01,  1.1379e+00,  4.5315e-01,  8.5246e-01,\n",
            "          1.1112e+00, -1.6072e-01, -1.1301e+00, -2.9255e-03, -2.7667e-01,\n",
            "         -1.3440e-01,  2.9796e-01,  1.5251e+00,  1.1946e+00, -7.2456e-01,\n",
            "          2.7255e-01,  6.1425e-01, -5.6450e-01,  4.3213e-01,  5.9250e-01,\n",
            "         -1.4969e+00, -1.6823e-01,  9.5053e-01, -2.1522e-01, -1.4202e+00,\n",
            "          2.8660e-01, -1.0355e-01, -6.4259e-01, -1.1136e+00,  3.5296e-01,\n",
            "         -1.1632e-01,  6.7657e-01,  1.6883e-01, -5.4889e-02, -1.0818e+00,\n",
            "         -2.9901e-01,  2.9806e-01, -2.4349e+00, -3.7111e-01, -7.0203e-02,\n",
            "         -2.5659e-01, -1.1622e+00, -6.6273e-02,  3.9327e-01, -6.2902e-01,\n",
            "         -8.1904e-01, -1.4031e+00,  5.2868e-02,  1.1758e+00, -7.6578e-02,\n",
            "         -1.1554e+00,  1.8884e-01, -2.3575e+00, -1.2882e+00, -5.3159e-01,\n",
            "          5.3302e-01, -1.0293e+00,  5.3685e-01, -1.8783e+00, -2.1776e+00,\n",
            "         -1.2217e+00, -1.0487e+00,  3.4001e-01, -2.1245e+00, -8.1668e-01,\n",
            "         -9.5509e-01, -8.2486e-01,  2.4928e+00,  1.8986e+00, -4.8711e-01,\n",
            "          1.5440e+00,  1.0272e+00,  1.7899e+00,  9.4084e-01,  7.7131e-01,\n",
            "         -1.1150e+00, -9.2724e-01, -7.7442e-01,  2.6163e-01,  4.0905e-02,\n",
            "          1.8873e+00, -6.5466e-01,  7.2295e-01, -6.0274e-01,  4.4510e-01,\n",
            "         -5.6051e-01, -1.1379e+00, -6.9870e-01,  7.2114e-01, -3.4821e-01,\n",
            "          1.0232e-01,  4.2888e-01, -1.7784e+00,  2.4118e-01,  4.1059e-01,\n",
            "         -1.1089e+00, -1.4021e+00,  2.9597e-02, -2.6634e-01, -3.2778e-01,\n",
            "         -3.2718e-02, -6.2191e-01,  1.0727e+00, -1.6313e+00, -1.0435e+00,\n",
            "         -1.3506e-01,  1.4193e+00, -6.9652e-01, -1.3911e+00,  8.6442e-01,\n",
            "         -2.5096e+00, -1.1081e+00,  1.3830e+00, -4.3349e-01, -1.5893e+00,\n",
            "          1.4212e+00,  9.6432e-01, -8.5318e-01,  9.0991e-01, -7.9500e-01,\n",
            "         -5.2353e-01,  5.0715e-02,  4.2546e-01,  2.3988e-01,  1.6613e+00,\n",
            "         -2.6251e-01,  2.3835e+00,  4.2510e-01, -1.5872e-01, -1.4468e+00,\n",
            "         -1.2405e+00, -7.6554e-01, -1.5418e-01,  2.3670e+00, -6.1288e-01,\n",
            "          1.2990e-01, -1.7615e+00, -5.6949e-01, -1.3377e+00, -4.0275e+00,\n",
            "          4.3273e-01,  1.6241e-01,  1.6659e+00, -2.9899e-01, -3.4733e-01,\n",
            "          5.5741e-02, -1.2231e+00, -8.5146e-01, -1.3800e+00,  4.0394e-01,\n",
            "          1.6587e+00, -6.6623e-01, -1.1220e-01, -5.1335e-04,  1.8534e-01,\n",
            "         -1.3011e+00,  1.2739e+00, -5.3071e-01,  2.6019e+00, -8.1556e-01,\n",
            "         -9.2830e-01,  1.3678e+00, -4.1851e-01, -1.0004e+00, -1.0626e+00,\n",
            "         -5.5911e-01, -9.0069e-01, -1.8507e+00, -9.8477e-01,  1.1769e+00,\n",
            "          3.0573e-01,  1.5497e+00,  2.3883e-01, -1.7999e-02, -1.0275e-01,\n",
            "          3.4694e-01,  8.7275e-01,  6.4780e-01, -9.2666e-01,  1.5344e+00,\n",
            "          7.0198e-01,  1.5551e-01,  3.2094e+00, -4.6390e-01,  7.6596e-01,\n",
            "         -1.2665e+00,  2.9290e-01,  1.9371e+00, -5.4292e-01, -6.6975e-02,\n",
            "         -3.1790e-01, -1.0281e+00,  2.7820e+00,  1.0583e+00, -4.4952e-01,\n",
            "          1.1575e+00,  4.0403e-01, -1.2361e+00,  9.3575e-01,  1.3205e+00,\n",
            "          3.3975e-01, -1.0872e+00, -1.5067e-01, -1.1213e+00,  1.2233e+00,\n",
            "          1.3292e+00, -2.1118e-01,  2.1071e+00, -9.6616e-01, -3.4366e-01,\n",
            "         -1.8000e+00, -1.4096e-01,  2.2795e-01,  7.3177e-02,  1.7980e+00,\n",
            "          9.4566e-01, -4.6695e-02, -6.6796e-01,  1.6478e-01, -2.0191e+00,\n",
            "         -6.2511e-01,  9.1436e-01, -7.8851e-01, -1.5550e+00,  8.0194e-01,\n",
            "         -1.0131e+00, -8.7945e-01,  1.1937e+00,  1.4797e+00, -7.0409e-01,\n",
            "          8.2093e-01, -1.2019e+00,  1.5037e-02,  1.0862e+00, -9.3589e-01,\n",
            "         -5.4812e-01,  4.0397e-01, -6.2616e-02,  1.6083e+00, -6.5356e-01,\n",
            "          1.2671e-01,  1.5009e-01, -1.1258e-01, -2.0483e+00,  1.4371e+00,\n",
            "          4.8666e-01,  1.2118e+00, -7.1917e-01,  7.9340e-01,  8.4493e-02,\n",
            "         -1.3110e-01, -1.3829e+00,  8.7514e-01,  1.0410e+00, -7.9668e-01,\n",
            "          1.3382e+00, -3.8279e-01,  9.0744e-02,  9.5888e-01,  4.5219e-01,\n",
            "          5.1321e-01, -3.0209e-01, -6.2552e-01, -4.3477e-02, -1.9278e-01,\n",
            "          2.0212e+00, -8.9324e-02,  7.4351e-01, -1.6773e+00,  2.3245e-01,\n",
            "          1.8709e-01, -6.7845e-01, -6.4066e-01, -2.8028e-01,  4.8315e-01,\n",
            "         -8.6103e-04, -5.6454e-01, -8.9965e-01,  9.6321e-01,  6.4455e-01,\n",
            "         -2.6666e+00,  1.3661e+00, -5.3669e-01,  4.3380e-01, -5.7040e-02,\n",
            "         -1.9651e+00,  1.6870e+00,  6.8380e-01,  1.0317e+00,  1.8497e+00,\n",
            "         -4.1009e-01, -2.4902e+00,  5.8362e-01,  6.7969e-01,  9.2735e-01,\n",
            "         -2.5480e-01,  8.9158e-01, -6.7517e-01,  1.3182e+00,  7.4805e-01,\n",
            "         -1.0969e+00,  2.0782e+00,  2.0090e-01, -4.4139e-01,  3.6632e-01,\n",
            "          6.3650e-01,  4.8139e-01, -1.1199e+00, -8.3656e-01,  7.8645e-01,\n",
            "          8.7915e-01, -1.5161e+00, -6.4722e-01, -1.4770e-02, -7.3286e-01,\n",
            "         -1.0693e+00, -7.2477e-01,  5.0201e-01, -7.6743e-01, -2.8855e-01,\n",
            "          1.4021e+00, -1.8727e+00, -1.3531e+00, -6.1146e-01,  4.7690e-01,\n",
            "         -1.8701e-01, -1.8574e+00, -7.9185e-01]], grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ],
      "source": [
        "token_id = tokenizer.token_to_id(\"I\")\n",
        "print(\"token_id:\", token_id)\n",
        "input_id = torch.tensor([token_id], dtype=torch.long)\n",
        "print(\"input_id 차원:\", input_id.shape)\n",
        "\n",
        "vector = embedding_vector(input_id)\n",
        "print(\"vector 차원:\", vector.shape)\n",
        "print(\"vector:\", vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f47d8d6",
      "metadata": {
        "id": "7f47d8d6"
      },
      "source": [
        "# 2. RNN/LSTM\n",
        "\n",
        "- 학습 목표\n",
        "  1. RNN/LSTM을 이용하여 문장 전체의 정보를 압축한 문맥 벡터에 대한 이해를 할 수 있다.\n",
        "  2. Encoder Decoder 구조를 통해 문맥 벡터를 이용하여 특정 task를 수행할 수 있다.\n",
        "- 학습 개념\n",
        "  1. RNN/LSTM\n",
        "  2. Encoder/Decoder\n",
        "- 진행하는 실습 요약\n",
        "  1. 간단한 RNN/LSTM을 구현한다.\n",
        "  2. 번역 task와 관련된 encoder decoder 구조를 구현한다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d6cfb8ca",
      "metadata": {
        "id": "d6cfb8ca"
      },
      "source": [
        "<blockquote>\n",
        "<b>🧠 Recurrent Neural Network(RNN)이란? </b><br>\n",
        "순차적(Sequential) 이전의 정보를 기억하여 현재의 정보를 처리하는 신경망 구조를 의미합니다.\n",
        "</blockquote>\n",
        "\n",
        "RNN이 갖는 특징은 다음과 같습니다.\n",
        "\n",
        "- 입력을 순차적으로 처리합니다.\n",
        "- RNN은 같은 가중치를 반복적으로 사용합니다.\n",
        "- 재귀적인 구조를 가집니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec4dfc5c",
      "metadata": {
        "id": "ec4dfc5c"
      },
      "source": [
        "그러면 이제부터 입력 텍스트를 RNN에 입력으로 넣어서 출력층의 결과값을 받아봅시다!\n",
        "\n",
        "텍스트를 입력으로 넣기 위해서는 위에서 보았듯, 워드 임베딩으로 변환해야 합니다.\n",
        "워드 임베딩을 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "id": "2b720ce0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2b720ce0",
        "outputId": "ba378684-ce59-40ed-e1ea-9e4453e7d722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "워드 임베딩 차원 : torch.Size([10000, 768])\n"
          ]
        }
      ],
      "source": [
        "word_embeddings: Tensor2D[VocabSize, EmbeddingSize] = nn.Embedding(vocab_size, 768)\n",
        "print(\"워드 임베딩 차원 :\", word_embeddings.weight.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f9be639",
      "metadata": {
        "id": "6f9be639"
      },
      "source": [
        "워드 임베딩 차원에 맞게 RNN을 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "id": "d6cf6ed2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6cf6ed2",
        "outputId": "38b36765-183d-4096-b6c1-5f2f5eb4f6be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h_0의 차원 : torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "input_size: int = word_embeddings.weight.size()[1] # RNN의 input size는 임베딩 벡터의 차원과 일치해야 합니다.\n",
        "hidden_size: int = 1024  # RNN의 hidden size\n",
        "num_layers: int = 1  # 쌓을 RNN layer의 개수\n",
        "bidirectional: bool = False  # 단방향 RNN\n",
        "\n",
        "rnn = nn.RNN(\n",
        "    input_size=input_size,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "# 초기 hidden state 초기화\n",
        "\n",
        "hidden_state_shape: int = (num_layers * (2 if bidirectional else 1), hidden_size)\n",
        "\n",
        "h_0: Tensor2D[Sequence, HiddenStates] = torch.zeros(hidden_state_shape)  # (num_layers * num_dirs, hidden_size)\n",
        "print(\"h_0의 차원 :\",h_0.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbb4f18e",
      "metadata": {
        "id": "cbb4f18e"
      },
      "source": [
        "입력 텍스트 데이터를 토크나이저를 사용하여 토큰화한 후, ids만 꺼냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "id": "bcf10c34",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcf10c34",
        "outputId": "ffb46fe0-afeb-4a2e-979f-d25ee83ea684"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6227, 7125, 3279, 9046,   18])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "text: str = \"나는 학교에 간다.\"\n",
        "\n",
        "# 토큰화를 진행합니다.\n",
        "encoded = tokenizer.encode(text)\n",
        "# 토큰의 ids만 꺼냅니다.\n",
        "input_ids: List[int] = encoded.ids\n",
        "\n",
        "# 텐서화를 합니다.\n",
        "input_ids: Tensor1D[Sequence] = torch.tensor(input_ids, dtype=torch.long)\n",
        "input_ids"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13935ca0",
      "metadata": {
        "id": "13935ca0"
      },
      "source": [
        "변환된 input_ids를 워드 임베딩으로 넣고\n",
        "워드 임베딩을 RNN의 입력으로 넣어 두 output을 얻습니다.\n",
        "\n",
        "1. `hidden_states`: 각 time step에 해당하는 hidden state들의 묶음.\n",
        "2. `h_n`: 모든 sequence를 거치고 나온 마지막 hidden state(`last hidden state`). hidden_states의 마지막과 동일."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "id": "97d65561",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97d65561",
        "outputId": "69a9eedf-5f52-40fa-9a95-23e16a40ae3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "워드 임베딩 차원 :  torch.Size([5, 768])\n",
            "hidden_states 차원 :  torch.Size([5, 1024])\n",
            "h_n 차원 :  torch.Size([1, 1024])\n",
            "hidden_states의 마지막과 h_n이 같습니다.\n"
          ]
        }
      ],
      "source": [
        "input_embeds: Tensor2D[Sequence, EmbeddingSize] = word_embeddings(input_ids)\n",
        "print(\"워드 임베딩 차원 : \", input_embeds.shape)  # (vocab_size, embedding_dim)\n",
        "outputs = rnn(input_embeds, h_0)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
        "\n",
        "# sequence_length: input_token의 길이(length), hidden size: hidden state 차원 수, num_layers: layer 개수, num_dirs: 방향의 개수\n",
        "print(\"hidden_states 차원 : \", hidden_states.shape)  # (sequence_length, d_h)\n",
        "print(\"h_n 차원 : \", h_n.shape)  # (num_layers * num_dirs, d_h) = (1, d_h)\n",
        "\n",
        "if torch.equal(hidden_states[-1].unsqueeze(0), h_n):\n",
        "    print(\"hidden_states의 마지막과 h_n이 같습니다.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ecc103e",
      "metadata": {
        "id": "7ecc103e"
      },
      "source": [
        "그러면 이러한 은닉 상태(hidden state)를 얻어서 어떠한 작업을 할 수 있을까요?\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 은닉 상태(hidden state)는 문장의 정보들을 압축적으로 저장합니다.</b><br>\n",
        "RNN layer를 통과하면서 문장 전체의 정보를 압축하게 되고 이러한 정보들은 hidden state에 담기게 됩니다. 이러한 hidden state는 문맥 벡터(context vector)로 사용됩니다.\n",
        "</blockquote>\n",
        "\n",
        "문맥 벡터(context vector)는 입력 문장의 정보들을 벡터상에 압축하여 저장한 것으로, 이를 통해 다양한 task를 수행할 수 있게 됩니다.\n",
        "\n",
        "여기서는 번역(translation) task를 수행하기 위해 hidden state를 사용하겠습니다.\n",
        "\n",
        "번역을 하기 위해서는 last hidden state를 다시 저희의 입력 데이터와 유사한 형태인 텍스트(토큰) id로 변환하는 layer가 필요합니다. 이를 저희는 Decoder라고 부릅니다.\n",
        "\n",
        "![image](https://raw.githubusercontent.com/Ssunbell/TIL/refs/heads/master/assets/Seq2SeqRNN.png)\n",
        "\n",
        "그러면 아래에서 Encoder와 Decoder를 연결하여 번역을 수행하는 모델을 구현하겠습니다.\n",
        "\n",
        "먼저 인코더를 구현하겠습니다. 위에서 구현한 rnn을 그대로 이용하여 클래스화를 진행하는 것과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "id": "f35ff084",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f35ff084",
        "outputId": "d602a337-1e4a-4233-8d7b-9ae31cde12ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states 차원 :  torch.Size([5, 1024])\n",
            "h_n 차원 :  torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "from abc import ABC, abstractmethod\n",
        "\n",
        "# 인코더 모델은 RNN을 사용합니다. 아래는 추상화 클래스입니다.\n",
        "class Encoder(nn.Module, ABC):\n",
        "    def __init__(self: \"Encoder\") -> None:\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self: \"Encoder\", input_ids: torch.Tensor) -> torch.Tensor:\n",
        "        # forward에서 실제로 인코딩을 수행하기 위한 레이어를 쌓습니다.\n",
        "        pass\n",
        "\n",
        "class RNNEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self: \"RNNEncoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "        self: \"RNNEncoder\",\n",
        "        input_ids: Tensor1D[Sequence]\n",
        "    ) -> Tuple[Tensor2D[Sequence, HiddenStates], Tensor2D[Layers, HiddenStates]]:\n",
        "        \"\"\"입력 토큰을 워드 임베딩을 통해 임베딩 변환을 합니다.\"\"\"\n",
        "        input_embeds = self.word_embeddings(input_ids)\n",
        "\n",
        "        \"\"\"RNN을 통해 입력 임베딩을 문맥 벡터(context vector)화 합니다.\"\"\"\n",
        "        outputs = self.rnn(input_embeds)\n",
        "        # TODO: 직접 구현해보세요!\n",
        "        # hidden_states: Tensor2D[Sequence, HiddenStates] = FIXME\n",
        "        # h_n: Tensor2D[Layers, HiddenStates] = FIXME\n",
        "        hidden_states, h_n = outputs\n",
        "        return hidden_states, h_n\n",
        "\n",
        "vocab_size = 30000\n",
        "embedding_dim = 768\n",
        "hidden_size = 1024  # RNN의 hidden size\n",
        "num_layers = 1  # 쌓을 RNN layer의 개수\n",
        "bidirectional = False  # 단방향 RNN\n",
        "\n",
        "rnn_encoder = RNNEncoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "outputs = rnn_encoder(input_ids)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1]\n",
        "print(\"hidden_states 차원 : \", hidden_states.shape)  # (L, B, d_h)\n",
        "print(\"h_n 차원 : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, B, d_h)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61b15bc9",
      "metadata": {
        "id": "61b15bc9"
      },
      "source": [
        "다음 디코더 부분을 구현하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "id": "a5a3b846",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5a3b846",
        "outputId": "ece0689d-67f8-4576-b75b-51ae9f06aba0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 디코더 모델 또한 RNN을 사용합니다.\n",
        "class Decoder(nn.Module, ABC):\n",
        "    def __init__(self: \"Decoder\") -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    @abstractmethod\n",
        "    def forward(self, input_ids: torch.Tensor, init_hidden_state: torch.Tensor) -> torch.Tensor:\n",
        "        pass\n",
        "\n",
        "class RNNDecoder(Decoder):\n",
        "    def __init__(\n",
        "        self: \"RNNDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "      self: \"RNNDecoder\",\n",
        "      init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
        "      max_len: int = 10\n",
        "  ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
        "      # --- fix: hx를 (L*D, B, H) 3D로 보장 ---\n",
        "      if init_hidden_state.dim() == 2:               # (L*D, H)로 들어온 경우\n",
        "          init_hidden_state = init_hidden_state.unsqueeze(1)  # -> (L*D, 1, H)\n",
        "      elif init_hidden_state.dim() == 1:             # (H,)로 들어온 경우(더 압축된 케이스)\n",
        "          init_hidden_state = init_hidden_state.unsqueeze(0).unsqueeze(1)  # -> (1,1,H)\n",
        "\n",
        "      # dtype/device도 맞춰주면 더 안전\n",
        "      init_hidden_state = init_hidden_state.to(\n",
        "          dtype=self.word_embeddings.weight.dtype,\n",
        "          device=self.word_embeddings.weight.device,\n",
        "      )\n",
        "      # ---------------------------------------\n",
        "\n",
        "      # 이하 기존 로직…\n",
        "      device = init_hidden_state.device\n",
        "      logits_list = []\n",
        "      input_token = torch.tensor([self.start_token_id], dtype=torch.long, device=device)\n",
        "      output_token_ids = [input_token.item()]\n",
        "      h_n = init_hidden_state\n",
        "\n",
        "      num_dirs = 2 if getattr(self.rnn, \"bidirectional\", False) else 1\n",
        "      H = self.rnn.hidden_size\n",
        "      L = self.rnn.num_layers\n",
        "\n",
        "      for _ in range(max_len):\n",
        "          if input_token.item() == self.end_token_id:\n",
        "              break\n",
        "\n",
        "          embedded = self.word_embeddings(input_token).unsqueeze(1)  # (1,E)->(1,1,E)\n",
        "          output, h_n = self.rnn(embedded, h_n)  # h_n: (L*D,1,H)\n",
        "\n",
        "          h_view = h_n.view(L, num_dirs, 1, H)\n",
        "          h_last = h_view[-1]  # (D,1,H)\n",
        "          concat_h_n = (torch.cat([h_last[0], h_last[1]], dim=-1).squeeze(0)\n",
        "                        if num_dirs == 2 else h_last[0].squeeze(0))  # (H*D,)\n",
        "\n",
        "          logit = self.fully_connected_layer(concat_h_n)  # (V,)\n",
        "          logits_list.append(logit)\n",
        "          input_token = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "\n",
        "      logits = (torch.stack(logits_list, dim=0)\n",
        "                if len(logits_list) > 0\n",
        "                else torch.empty(0, self.fully_connected_layer.out_features, device=device))\n",
        "      return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024  # RNN의 hidden size\n",
        "num_layers: int = 1  # 쌓을 RNN layer의 개수\n",
        "bidirectional: bool = False  # 단방향 RNN\n",
        "\n",
        "rnn_decoder = RNNDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "logits, output_token_ids = rnn_decoder(h_n)\n",
        "output_texts = tokenizer.decode(output_token_ids)\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a43d683",
      "metadata": {
        "id": "2a43d683"
      },
      "source": [
        "이제 구현한 encoder와 decoder를 연결하여 seq2seq 모델을 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "55b85dfe",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55b85dfe",
        "outputId": "4c884e21-b8e6-40ac-8ea6-63bf198c6bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##99999999 안보게 성경 줬 예상이요소가 멋집니다 상상을 얻는 프랑스영화는\n"
          ]
        }
      ],
      "source": [
        "class RNNSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"RNNSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"RNNSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, context_vector = self.encoder(input_ids) # encoder에서 생성한 context_vector(h_n)을 decoder layer로 전달\n",
        "        logits, output_tokens = self.decoder(context_vector)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = RNNSeq2Seq(rnn_encoder, rnn_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36e7487e",
      "metadata": {
        "id": "36e7487e"
      },
      "source": [
        "<blockquote>\n",
        "<b>🤔 결과값이 이상해요</b><br>\n",
        "데이터로 충분히 학습을 하지 않아서 그렇습니다. 여기서는 모델의 구조에 대해서 집중하고 추후에 모델을 학습하는 과정을 경험해보겠습니다.\n",
        "</blockquote>\n",
        "\n",
        "저희는 Sequence to Sequence(Encoder - Decoder) 구조를 이용하여 텍스트를 생성해보았습니다.\n",
        "\n",
        "Seq2Seq 구조 내에서 실제 워드 임베딩을 컨텍스트 벡터로 변환하고, 그 변환된 컨텍스트 벡터를 텍스트(토큰)으로 변환하는 과정에서 쓰인 모델은 RNN이였습니다.\n",
        "\n",
        "RNN뿐만 아니라 LSTM, 어텐션 등을 사용하여 Seq2Seq 구조를 구현할 수 있습니다.\n",
        "\n",
        "전체적인 큰 틀은 그대로 유지한 채, RNN 모듈만 바꿔주기만 하면 됩니다.\n",
        "\n",
        "그러면 이제부터 LSTM으로 다시 한번 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8758c710",
      "metadata": {
        "id": "8758c710"
      },
      "source": [
        "RNN과 LSTM의 가장 큰 차이점은 LSTM에는 cell state가 추가된다는 점입니다.\n",
        "\n",
        "장기 기억을 담당하는 cell state를 통해 좀더 성능을 높일 수 있습니다.\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 Key point!</b><br>\n",
        "모델의 아키텍쳐마다 모델의 입출력이 달라집니다. 모델의 입력과 출력이 어떻게 나오는지에 대해서 이해하는 것이 중요합니다.\n",
        "</blockquote>\n",
        "\n",
        "그러면 Encoder에서 LSTM을 적용해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "bf861480",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bf861480",
        "outputId": "a22666a2-b589-4979-9f1f-3ff2d68c7caf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "hidden_states 차원 :  torch.Size([5, 1024])\n",
            "h_n 차원 :  torch.Size([1, 1024])\n",
            "c_n 차원 :  torch.Size([1, 1024])\n"
          ]
        }
      ],
      "source": [
        "class LSTMEncoder(Encoder):\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "    def forward(\n",
        "      self: \"LSTMEncoder\",\n",
        "      input_ids: torch.LongTensor,   # [S,B] or [B,S]\n",
        "  ):\n",
        "      # 임베딩\n",
        "      input_embeds = self.word_embeddings(input_ids)  # [S,B,E] or [B,S,E]\n",
        "\n",
        "      # LSTM은 batch_first=False 이므로 [S,B,E] 필요 → [B,S,E]로 들어오면 전치\n",
        "      if input_embeds.dim() == 3 and input_embeds.shape[0] < input_embeds.shape[1]:\n",
        "          input_embeds = input_embeds.transpose(0, 1)\n",
        "\n",
        "      # LSTM 실행\n",
        "      hidden_states, (h_n, c_n) = self.lstm(input_embeds)\n",
        "      # hidden_states: [S, B, D*H],  h_n,c_n: [L*D, B, H]\n",
        "\n",
        "      return hidden_states, (h_n, c_n)\n",
        "\n",
        "vocab_size = 30000\n",
        "embedding_dim = 768\n",
        "hidden_size = 1024  # RNN의 hidden size\n",
        "num_layers = 1  # 쌓을 RNN layer의 개수\n",
        "bidirectional = False  # 단방향 RNN\n",
        "\n",
        "lstm_encoder = LSTMEncoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional\n",
        ")\n",
        "\n",
        "outputs = lstm_encoder(input_ids)\n",
        "hidden_states: Tensor2D[Sequence, HiddenStates] = outputs[0]\n",
        "h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "print(\"hidden_states 차원 : \", hidden_states.shape)  # (L, B, d_h)\n",
        "print(\"h_n 차원 : \", h_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
        "print(\"c_n 차원 : \", c_n.shape)  # (num_layers*num_dirs, B, d_h) = (1, d_h)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40d7ab4d",
      "metadata": {
        "id": "40d7ab4d"
      },
      "source": [
        "이번에는 LSTM을 사용하여 Decoder Layer를 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "77ba9e94",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77ba9e94",
        "outputId": "289f1fd8-e264-4baa-d928-8a6dd2f40262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마음속 지루하다고자동맛에뇬 세월이겠구만 흥행에꼭보세요 나중\n"
          ]
        }
      ],
      "source": [
        "class LSTMDecoder(Decoder):\n",
        "    def __init__(\n",
        "        self: \"LSTMDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(\n",
        "        self: \"LSTMDecoder\",\n",
        "        init_hidden_state: Tensor2D[Layers, HiddenStates],\n",
        "        init_cell_state: Tensor2D[Layers, HiddenStates],\n",
        "        max_len: int = 10\n",
        "    ) -> Tuple[Tensor2D[MaxLength, VocabSize], List[int]]:\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensor에서 item()을 사용하여 int로 변환합니다.\n",
        "        h_n = init_hidden_state # h_n은 encoder의 h_0와 동일한 역할을 합니다.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # 문장의 종료를 의미하는 special token([SEP])이 나왔다면 추론(생성)을 종료합니다.\n",
        "                break\n",
        "\n",
        "            \"\"\"직전 토큰만 입력으로 넣고 생성한 context vector는 logits에 저장합니다.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # 직전 입력 토큰만 사용 [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # 여기서는 layer 갯수가 1이고, bidirectional이 False이므로 squeeze를 사용해도 무방합니다. (원래는 torch.cat으로 h_n을 합치는 작업이 필요합니다.)\n",
        "\n",
        "            \"\"\"fully connected layer를 통해 [VocabSize]의 logit을 생성합니다.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(concat_h_n)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"가장 높은 점수값을 가진 토큰을 선택합니다.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        \"\"\"리스트의 logits를 torch의 Tensor로 변경합니다.\"\"\"\n",
        "        logits = torch.stack(logits, dim=0)  # [max_len, vocab_size]\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNN의 hidden size\n",
        "num_layers: int = 1 # 쌓을 RNN layer의 개수\n",
        "bidirectional: bool = False # 단방향 RNN\n",
        "\n",
        "lstm_decoder = LSTMDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = lstm_decoder(h_n, c_n)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c8db0e2",
      "metadata": {
        "id": "8c8db0e2"
      },
      "source": [
        "Encoder와 Decoder를 사용하여 Seq2Seq 모델을 구현해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "id": "fddfe053",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fddfe053",
        "outputId": "6328a32c-7654-43ff-a872-6ac6797a7b32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "마음속 지루하다고자동맛에뇬 세월이겠구만 흥행에꼭보세요 나중\n"
          ]
        }
      ],
      "source": [
        "class LSTMSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"LSTMSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"LSTMSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (context_vector, cell_states) = self.encoder(input_ids) # encoder에서 생성한 context_vector(h_n)을 decoder layer로 전달\n",
        "        logits, output_tokens = self.decoder(context_vector, cell_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = LSTMSeq2Seq(lstm_encoder, lstm_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0391cd8a",
      "metadata": {
        "id": "0391cd8a"
      },
      "source": [
        "# 3. Attention Mechanism\n",
        "\n",
        "- 학습 목표\n",
        "  1. Luong Attention(Dot Attention)을 구현할 수 있다.\n",
        "  2. Attention을 이용하여 Decoder를 구현할 수 있다.\n",
        "- 학습 개념\n",
        "  1. Luong Attention\n",
        "- 진행하는 실습 요약\n",
        "  1. Luong Attention을 구현한다.\n",
        "  2. Seq2Seq 구조에 들어갈 Decoder를 구현한다.\n",
        "\n",
        "\n",
        "이번에는 Attention을 사용한 seq2seq 모델을 구현해보겠습니다.\n",
        "\n",
        "<blockquote>\n",
        "<b>🧠 Attention Mechanism</b><br>\n",
        "현재 구현할 seq2seq 모델에서의 Attention은 최근 사용하는 attention은 아닙니다. 최근의 Transformers 모델들은 Multi-Head Scaled Dot-Product Attention을 사용합니다. 해당 내용은 과제에서 다룰 예정입니다.\n",
        "</blockquote>\n",
        "\n",
        "1. 전체적인 Seq2Seq 모델의 구조는 동일합니다.\n",
        "2. Encoder에서 context vector를 얻을 때, LSTM을 사용하는 Encoder 모듈을 그대로 사용합니다.\n",
        "3. Decoder에서 output token을 생성할 때, attention mechanism을 추가합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ad3807ee",
      "metadata": {
        "id": "ad3807ee"
      },
      "source": [
        "그러면 우선 Dot Attention(Luong attention)을 먼저 구현합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "id": "70059257",
      "metadata": {
        "id": "70059257"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class LuongAttention(nn.Module):\n",
        "    def __init__(self: \"LuongAttention\", hidden_size: int):\n",
        "        super().__init__()\n",
        "        self.W_a = nn.Linear(hidden_size, hidden_size, bias=False)\n",
        "\n",
        "    @torch.no_grad()  # 학습 시 제거하세요\n",
        "    def forward(\n",
        "        self:\"LuongAttention\",\n",
        "        h_t: Tensor1D[HiddenStates],\n",
        "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
        "    ) -> Tuple[Tensor1D[HiddenStates], Tensor1D[Sequence]]:\n",
        "        \"\"\"hidden state를 W_a에 projection하여 Wa_ht를 구합니다.\"\"\"\n",
        "        Wa_ht: Tensor1D[HiddenStates] = self.W_a(h_t)\n",
        "\n",
        "        \"\"\"encoder_outputs와 Wa_ht를 내적하여 attention score를 구합니다.\"\"\"\n",
        "        # TODO: 직접 구현해보세요!\n",
        "        # attention_score: Tensor1D[Sequence] = FIXME\n",
        "        attention_score = torch.mv(encoder_outputs, Wa_ht)\n",
        "        \"\"\"attention score를 softmax layer에 통과시켜 attention weights(attention distribution)을 구합니다.\"\"\"\n",
        "        # TODO: 직접 구현해보세요!\n",
        "        # attention_weights: Tensor1D[Sequence] = FIXME\n",
        "        attention_weights = F.softmax(attention_score, dim=0)\n",
        "        \"\"\"각 encoder의 attention weights와 encoder의 hidden state를 내적하여 context vector(attention value)를 구합니다.\"\"\"\n",
        "        # TODO: 직접 구현해보세요!\n",
        "        # context_vector: Tensor1D[HiddenStates] = FIXME\n",
        "        context_vector = attention_weights.unsqueeze(0) @ encoder_outputs\n",
        "        context_vector = context_vector.squeeze(0)\n",
        "        return context_vector, attention_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "df83103d",
      "metadata": {
        "id": "df83103d"
      },
      "source": [
        "<blockquote>\n",
        "<b>🤔 엇 여기서도 context vector가 나오네요?</b><br>\n",
        "네 그렇습니다. 과거에는 encoder의 마지막 hidden state(h_n)을 context vector라고 불렀습니다. 하지만, attention이 나오면서 context vector는 각 디코딩 시점마다 인코더의 모든 hidden states에 대한 어텐션 가중합이라고 생각해주시면 됩니다.\n",
        "</blockquote>\n",
        "\n",
        "구현한 attention mechanism을 이용하여 Decoder layer에 적용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "id": "e2abb3bc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2abb3bc",
        "outputId": "78a78abf-14f1-46c6-adcb-b04b18c651f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사수 여운 감정을동영상 묻히 1편을맥 영화중에 지상희는\n"
          ]
        }
      ],
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(\n",
        "        self: \"AttentionDecoder\",\n",
        "        vocab_size: int,\n",
        "        embedding_dim: int,\n",
        "        hidden_size: int,\n",
        "        num_layers: int,\n",
        "        bidirectional: bool,\n",
        "        start_token_id: int,\n",
        "        end_token_id: int,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.start_token_id = start_token_id\n",
        "        self.end_token_id = end_token_id\n",
        "        # word embedding layer\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        # rnn layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=embedding_dim,\n",
        "            hidden_size=hidden_size,\n",
        "            num_layers=num_layers,\n",
        "            bidirectional=bidirectional,\n",
        "        )\n",
        "\n",
        "        \"\"\"attention을 추가합니다.\"\"\"\n",
        "        self.attn = LuongAttention(hidden_size)\n",
        "        \"\"\"context vector을 입력으로 받는 trainable weights\"\"\"\n",
        "        self.W_c = nn.Linear(hidden_size * 2, hidden_size)\n",
        "        # fully connected layer\n",
        "        self.fully_connected_layer = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    @torch.no_grad()  # 학습 시 제거\n",
        "    def forward(\n",
        "        self:\"AttentionDecoder\",\n",
        "        init_hidden_state: Tensor1D[HiddenStates],\n",
        "        init_cell_state: Tensor1D[HiddenStates],\n",
        "        encoder_outputs: Tensor2D[Sequence, HiddenStates],\n",
        "        max_len: int = 10,\n",
        "    ):\n",
        "        logits: List[Tensor1D[VocabSize]] = []\n",
        "        input_token: Tensor1D[Token] = torch.tensor([self.start_token_id], dtype=torch.long)\n",
        "        output_token_ids: List[int] = [input_token.item()] # tensor에서 item()을 사용하여 int로 변환합니다.\n",
        "        h_n = init_hidden_state # h_n은 encoder의 h_0와 동일한 역할을 합니다.\n",
        "        c_n = init_cell_state\n",
        "\n",
        "        for _ in range(max_len):\n",
        "            if input_token == self.end_token_id:\n",
        "                # 문장의 종료를 의미하는 special token([SEP])이 나왔다면 추론(생성)을 종료합니다.\n",
        "                break\n",
        "\n",
        "            \"\"\"직전 토큰만 입력으로 넣고 생성한 context vector는 logits에 저장합니다.\"\"\"\n",
        "            embedded: Tensor2D[Token, EmbeddingSize] = self.word_embeddings(input_token)  # 직전 입력 토큰만 사용 [1, embedding_dim]\n",
        "            outputs = self.lstm(embedded, (h_n, c_n))   # outputs: [S,B,D*H] or [B,S,D*H]\n",
        "            h_n: Tensor2D[Layers, HiddenStates] = outputs[1][0]\n",
        "            c_n: Tensor2D[Layers, HiddenStates] = outputs[1][1]\n",
        "\n",
        "            concat_h_n: Tensor1D[HiddenStates] = h_n.squeeze(0) # 여기서는 layer 갯수가 1이고, bidirectional이 False이므로 squeeze를 사용해도 무방합니다. (원래는 torch.cat으로 h_n을 합치는 작업이 필요합니다.)\n",
        "\n",
        "            # 어텐션\n",
        "            context_vector, attention_weights = self.attn(concat_h_n, encoder_outputs)\n",
        "\n",
        "            \"\"\"h_n(은닉 상태)와 context_vector를 연결합니다. (Concatenate)\"\"\"\n",
        "            v_t: Tensor1D[HiddenStates * 2] = torch.cat([concat_h_n, context_vector], dim=-1)\n",
        "\n",
        "            \"\"\"v_t를 trainable weights를 통과시키고 tanh를 적용합니다.\"\"\"\n",
        "            # TODO: 직접 구현해보세요!\n",
        "            # attentional_hidden_state: Tensor1D[HiddenStates] = FIXME\n",
        "            try:\n",
        "                attentional_hidden_state = torch.tanh(self.attn_proj(v_t))  # [H]\n",
        "            except AttributeError:\n",
        "                # attn_proj가 아직 없으면 (2H -> H)로 1회 생성해서 등록\n",
        "                self.attn_proj = nn.Linear(v_t.size(-1), h_n.size(-1), bias=True).to(v_t.device)\n",
        "                attentional_hidden_state = torch.tanh(self.attn_proj(v_t))  # [H]\n",
        "            \"\"\"fully connected layer를 통해 [VocabSize]의 logit을 생성합니다.\"\"\"\n",
        "            logit: Tensor1D[VocabSize] = self.fully_connected_layer(attentional_hidden_state)\n",
        "            logits.append(logit)\n",
        "\n",
        "            \"\"\"가장 높은 점수값을 가진 토큰을 선택합니다.\"\"\"\n",
        "            input_token: Tensor1D[Token] = torch.argmax(logit, dim=-1).unsqueeze(0)\n",
        "            output_token_ids.append(input_token.item())\n",
        "\n",
        "        logits = torch.stack(logits, dim=0) if logits else torch.empty(0, self.out.out_features)\n",
        "\n",
        "        return logits, output_token_ids\n",
        "\n",
        "start_token_id: int = tokenizer.encode(\"[CLS]\").ids[0]\n",
        "end_token_id: int = tokenizer.encode(\"[SEP]\").ids[0]\n",
        "\n",
        "vocab_size: int = 30000\n",
        "embedding_dim: int = 768\n",
        "hidden_size: int = 1024 # RNN의 hidden size\n",
        "num_layers: int = 1 # 쌓을 RNN layer의 개수\n",
        "bidirectional: bool = False # 단방향 RNN\n",
        "\n",
        "attention_decoder = AttentionDecoder(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_size=hidden_size,\n",
        "    num_layers=num_layers,\n",
        "    bidirectional=bidirectional,\n",
        "    start_token_id=start_token_id,\n",
        "    end_token_id=end_token_id,\n",
        ")\n",
        "\n",
        "logits, output_tokens = attention_decoder(h_n, c_n, hidden_states)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bd266f15",
      "metadata": {
        "id": "bd266f15"
      },
      "source": [
        "Decoder layer를 구현했으니 이제 Seq2Seq 모델에 적용해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "id": "036db196",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "036db196",
        "outputId": "5b6faf80-7a6e-45f4-f141-3748a610e93a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사수 여운 감정을동영상 묻히 1편을맥 영화중에 지상희는\n"
          ]
        }
      ],
      "source": [
        "class AttentionSeq2Seq(nn.Module):\n",
        "    def __init__(self: \"AttentionSeq2Seq\", encoder: nn.Module, decoder: nn.Module) -> None:\n",
        "        super().__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def forward(self: \"AttentionSeq2Seq\", input_ids: Tensor1D[Sequence]):\n",
        "        hidden_states, (last_hidden_state, cell_states) = self.encoder(input_ids) # encoder에서 생성한 h_n을 decoder layer로 전달\n",
        "        logits, output_tokens = self.decoder(last_hidden_state, cell_states, hidden_states)\n",
        "\n",
        "        return logits, output_tokens\n",
        "\n",
        "seq2seq = AttentionSeq2Seq(lstm_encoder, attention_decoder)\n",
        "logits, output_tokens = seq2seq(input_ids)\n",
        "output_token_ids = logits.argmax(dim=-1)\n",
        "output_texts = tokenizer.decode(output_token_ids.tolist())\n",
        "print(output_texts)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7438c86",
      "metadata": {
        "id": "a7438c86"
      },
      "source": [
        "# 4. Huggingface 라이브러리 활용\n",
        "\n",
        "- 학습 목표\n",
        "  1. huggingface 라이브러리를 이용하여 기학습된 모델을 불러올 수 있다.\n",
        "  2. 기학습된 모델을 이용하여 추론을 할 수 있다.\n",
        "- 학습 개념\n",
        "  1. huggingface\n",
        "- 진행하는 실습 요약\n",
        "  1. HuggingFace Hub에서 한국어-영어 번역을 위해 사전학습된 모델과 토크나이저를 불러오는 코드(from_pretrained)를 완성\n",
        "  2. 불러온 토크나이저로 입력 문장을 인코딩하고, model.generate() 함수를 사용해 번역 결과를 생성하는 코드를 완성\n",
        "  3. 과제 2에서 사용한 번역 모델이 실제로 인코더와 디코더를 모두 가지고 있는지 코드로 확인\n",
        "\n",
        "huggingface는 글로벌 최대 AI 모델 오픈소스 커뮤니티입니다. 과거에는 자연어처리 모델만 있었지만, 최근에는 비전, 로봇 등 다양한 오픈소스 모델들을 지원합니다.\n",
        "\n",
        "여기서 Seq2Seq 아키텍쳐 구조에서 미리 학습한 모델을 불러와서 추론을 해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "87698cfe",
      "metadata": {
        "id": "87698cfe"
      },
      "source": [
        "아래 코드를 실행하여 모델과 토크나이저를 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "id": "28f35c6a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28f35c6a",
        "outputId": "762cef84-d09b-451a-bbb7-27c4a6dfd259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "model_name = \"Helsinki-NLP/opus-mt-ko-en\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1d16c583",
      "metadata": {
        "id": "1d16c583"
      },
      "source": [
        "불러온 모델이 Encoder와 Decoder 모듈을 가지고 있는지 확인하는 2가지 방법이 있습니다.\n",
        "\n",
        "1. `print(model)`을 사용하여 모델의 구조를 확인합니다. 시각적으로 잘 정돈된 모델 구조를 확인할 수 있습니다.\n",
        "2. `model.named_parameters()`를 사용하여 실제 클래스를 확인할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "id": "f818e2ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f818e2ea",
        "outputId": "a0055db1-7fa3-4915-8aad-a83d52223062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MarianMTModel(\n",
            "  (model): MarianModel(\n",
            "    (shared): Embedding(65001, 512, padding_idx=65000)\n",
            "    (encoder): MarianEncoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianEncoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): SiLU()\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): MarianDecoder(\n",
            "      (embed_tokens): Embedding(65001, 512, padding_idx=65000)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianDecoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (activation_fn): SiLU()\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=65001, bias=False)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "id": "bbaf7975",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bbaf7975",
        "outputId": "841e0dc6-d75d-4409-d0e1-d2943ed2c6bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model.shared.weight\n",
            "model.encoder.embed_positions.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.weight\n",
            "model.encoder.layers.0.self_attn.k_proj.bias\n",
            "model.encoder.layers.0.self_attn.v_proj.weight\n",
            "model.encoder.layers.0.self_attn.v_proj.bias\n",
            "model.encoder.layers.0.self_attn.q_proj.weight\n",
            "model.encoder.layers.0.self_attn.q_proj.bias\n",
            "model.encoder.layers.0.self_attn.out_proj.weight\n",
            "model.encoder.layers.0.self_attn.out_proj.bias\n",
            "model.encoder.layers.0.self_attn_layer_norm.weight\n",
            "model.encoder.layers.0.self_attn_layer_norm.bias\n",
            "model.encoder.layers.0.fc1.weight\n",
            "model.encoder.layers.0.fc1.bias\n",
            "model.encoder.layers.0.fc2.weight\n",
            "model.encoder.layers.0.fc2.bias\n",
            "model.encoder.layers.0.final_layer_norm.weight\n",
            "model.encoder.layers.0.final_layer_norm.bias\n",
            "model.encoder.layers.1.self_attn.k_proj.weight\n",
            "model.encoder.layers.1.self_attn.k_proj.bias\n",
            "model.encoder.layers.1.self_attn.v_proj.weight\n",
            "model.encoder.layers.1.self_attn.v_proj.bias\n",
            "model.encoder.layers.1.self_attn.q_proj.weight\n",
            "model.encoder.layers.1.self_attn.q_proj.bias\n",
            "model.encoder.layers.1.self_attn.out_proj.weight\n",
            "model.encoder.layers.1.self_attn.out_proj.bias\n",
            "model.encoder.layers.1.self_attn_layer_norm.weight\n",
            "model.encoder.layers.1.self_attn_layer_norm.bias\n",
            "model.encoder.layers.1.fc1.weight\n",
            "model.encoder.layers.1.fc1.bias\n",
            "model.encoder.layers.1.fc2.weight\n",
            "model.encoder.layers.1.fc2.bias\n",
            "model.encoder.layers.1.final_layer_norm.weight\n",
            "model.encoder.layers.1.final_layer_norm.bias\n",
            "model.encoder.layers.2.self_attn.k_proj.weight\n",
            "model.encoder.layers.2.self_attn.k_proj.bias\n",
            "model.encoder.layers.2.self_attn.v_proj.weight\n",
            "model.encoder.layers.2.self_attn.v_proj.bias\n",
            "model.encoder.layers.2.self_attn.q_proj.weight\n",
            "model.encoder.layers.2.self_attn.q_proj.bias\n",
            "model.encoder.layers.2.self_attn.out_proj.weight\n",
            "model.encoder.layers.2.self_attn.out_proj.bias\n",
            "model.encoder.layers.2.self_attn_layer_norm.weight\n",
            "model.encoder.layers.2.self_attn_layer_norm.bias\n",
            "model.encoder.layers.2.fc1.weight\n",
            "model.encoder.layers.2.fc1.bias\n",
            "model.encoder.layers.2.fc2.weight\n",
            "model.encoder.layers.2.fc2.bias\n",
            "model.encoder.layers.2.final_layer_norm.weight\n",
            "model.encoder.layers.2.final_layer_norm.bias\n",
            "model.encoder.layers.3.self_attn.k_proj.weight\n",
            "model.encoder.layers.3.self_attn.k_proj.bias\n",
            "model.encoder.layers.3.self_attn.v_proj.weight\n",
            "model.encoder.layers.3.self_attn.v_proj.bias\n",
            "model.encoder.layers.3.self_attn.q_proj.weight\n",
            "model.encoder.layers.3.self_attn.q_proj.bias\n",
            "model.encoder.layers.3.self_attn.out_proj.weight\n",
            "model.encoder.layers.3.self_attn.out_proj.bias\n",
            "model.encoder.layers.3.self_attn_layer_norm.weight\n",
            "model.encoder.layers.3.self_attn_layer_norm.bias\n",
            "model.encoder.layers.3.fc1.weight\n",
            "model.encoder.layers.3.fc1.bias\n",
            "model.encoder.layers.3.fc2.weight\n",
            "model.encoder.layers.3.fc2.bias\n",
            "model.encoder.layers.3.final_layer_norm.weight\n",
            "model.encoder.layers.3.final_layer_norm.bias\n",
            "model.encoder.layers.4.self_attn.k_proj.weight\n",
            "model.encoder.layers.4.self_attn.k_proj.bias\n",
            "model.encoder.layers.4.self_attn.v_proj.weight\n",
            "model.encoder.layers.4.self_attn.v_proj.bias\n",
            "model.encoder.layers.4.self_attn.q_proj.weight\n",
            "model.encoder.layers.4.self_attn.q_proj.bias\n",
            "model.encoder.layers.4.self_attn.out_proj.weight\n",
            "model.encoder.layers.4.self_attn.out_proj.bias\n",
            "model.encoder.layers.4.self_attn_layer_norm.weight\n",
            "model.encoder.layers.4.self_attn_layer_norm.bias\n",
            "model.encoder.layers.4.fc1.weight\n",
            "model.encoder.layers.4.fc1.bias\n",
            "model.encoder.layers.4.fc2.weight\n",
            "model.encoder.layers.4.fc2.bias\n",
            "model.encoder.layers.4.final_layer_norm.weight\n",
            "model.encoder.layers.4.final_layer_norm.bias\n",
            "model.encoder.layers.5.self_attn.k_proj.weight\n",
            "model.encoder.layers.5.self_attn.k_proj.bias\n",
            "model.encoder.layers.5.self_attn.v_proj.weight\n",
            "model.encoder.layers.5.self_attn.v_proj.bias\n",
            "model.encoder.layers.5.self_attn.q_proj.weight\n",
            "model.encoder.layers.5.self_attn.q_proj.bias\n",
            "model.encoder.layers.5.self_attn.out_proj.weight\n",
            "model.encoder.layers.5.self_attn.out_proj.bias\n",
            "model.encoder.layers.5.self_attn_layer_norm.weight\n",
            "model.encoder.layers.5.self_attn_layer_norm.bias\n",
            "model.encoder.layers.5.fc1.weight\n",
            "model.encoder.layers.5.fc1.bias\n",
            "model.encoder.layers.5.fc2.weight\n",
            "model.encoder.layers.5.fc2.bias\n",
            "model.encoder.layers.5.final_layer_norm.weight\n",
            "model.encoder.layers.5.final_layer_norm.bias\n",
            "model.decoder.embed_positions.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.weight\n",
            "model.decoder.layers.0.self_attn.k_proj.bias\n",
            "model.decoder.layers.0.self_attn.v_proj.weight\n",
            "model.decoder.layers.0.self_attn.v_proj.bias\n",
            "model.decoder.layers.0.self_attn.q_proj.weight\n",
            "model.decoder.layers.0.self_attn.q_proj.bias\n",
            "model.decoder.layers.0.self_attn.out_proj.weight\n",
            "model.decoder.layers.0.self_attn.out_proj.bias\n",
            "model.decoder.layers.0.self_attn_layer_norm.weight\n",
            "model.decoder.layers.0.self_attn_layer_norm.bias\n",
            "model.decoder.layers.0.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.0.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.0.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.0.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.0.fc1.weight\n",
            "model.decoder.layers.0.fc1.bias\n",
            "model.decoder.layers.0.fc2.weight\n",
            "model.decoder.layers.0.fc2.bias\n",
            "model.decoder.layers.0.final_layer_norm.weight\n",
            "model.decoder.layers.0.final_layer_norm.bias\n",
            "model.decoder.layers.1.self_attn.k_proj.weight\n",
            "model.decoder.layers.1.self_attn.k_proj.bias\n",
            "model.decoder.layers.1.self_attn.v_proj.weight\n",
            "model.decoder.layers.1.self_attn.v_proj.bias\n",
            "model.decoder.layers.1.self_attn.q_proj.weight\n",
            "model.decoder.layers.1.self_attn.q_proj.bias\n",
            "model.decoder.layers.1.self_attn.out_proj.weight\n",
            "model.decoder.layers.1.self_attn.out_proj.bias\n",
            "model.decoder.layers.1.self_attn_layer_norm.weight\n",
            "model.decoder.layers.1.self_attn_layer_norm.bias\n",
            "model.decoder.layers.1.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.1.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.1.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.1.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.1.fc1.weight\n",
            "model.decoder.layers.1.fc1.bias\n",
            "model.decoder.layers.1.fc2.weight\n",
            "model.decoder.layers.1.fc2.bias\n",
            "model.decoder.layers.1.final_layer_norm.weight\n",
            "model.decoder.layers.1.final_layer_norm.bias\n",
            "model.decoder.layers.2.self_attn.k_proj.weight\n",
            "model.decoder.layers.2.self_attn.k_proj.bias\n",
            "model.decoder.layers.2.self_attn.v_proj.weight\n",
            "model.decoder.layers.2.self_attn.v_proj.bias\n",
            "model.decoder.layers.2.self_attn.q_proj.weight\n",
            "model.decoder.layers.2.self_attn.q_proj.bias\n",
            "model.decoder.layers.2.self_attn.out_proj.weight\n",
            "model.decoder.layers.2.self_attn.out_proj.bias\n",
            "model.decoder.layers.2.self_attn_layer_norm.weight\n",
            "model.decoder.layers.2.self_attn_layer_norm.bias\n",
            "model.decoder.layers.2.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.2.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.2.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.2.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.2.fc1.weight\n",
            "model.decoder.layers.2.fc1.bias\n",
            "model.decoder.layers.2.fc2.weight\n",
            "model.decoder.layers.2.fc2.bias\n",
            "model.decoder.layers.2.final_layer_norm.weight\n",
            "model.decoder.layers.2.final_layer_norm.bias\n",
            "model.decoder.layers.3.self_attn.k_proj.weight\n",
            "model.decoder.layers.3.self_attn.k_proj.bias\n",
            "model.decoder.layers.3.self_attn.v_proj.weight\n",
            "model.decoder.layers.3.self_attn.v_proj.bias\n",
            "model.decoder.layers.3.self_attn.q_proj.weight\n",
            "model.decoder.layers.3.self_attn.q_proj.bias\n",
            "model.decoder.layers.3.self_attn.out_proj.weight\n",
            "model.decoder.layers.3.self_attn.out_proj.bias\n",
            "model.decoder.layers.3.self_attn_layer_norm.weight\n",
            "model.decoder.layers.3.self_attn_layer_norm.bias\n",
            "model.decoder.layers.3.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.3.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.3.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.3.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.3.fc1.weight\n",
            "model.decoder.layers.3.fc1.bias\n",
            "model.decoder.layers.3.fc2.weight\n",
            "model.decoder.layers.3.fc2.bias\n",
            "model.decoder.layers.3.final_layer_norm.weight\n",
            "model.decoder.layers.3.final_layer_norm.bias\n",
            "model.decoder.layers.4.self_attn.k_proj.weight\n",
            "model.decoder.layers.4.self_attn.k_proj.bias\n",
            "model.decoder.layers.4.self_attn.v_proj.weight\n",
            "model.decoder.layers.4.self_attn.v_proj.bias\n",
            "model.decoder.layers.4.self_attn.q_proj.weight\n",
            "model.decoder.layers.4.self_attn.q_proj.bias\n",
            "model.decoder.layers.4.self_attn.out_proj.weight\n",
            "model.decoder.layers.4.self_attn.out_proj.bias\n",
            "model.decoder.layers.4.self_attn_layer_norm.weight\n",
            "model.decoder.layers.4.self_attn_layer_norm.bias\n",
            "model.decoder.layers.4.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.4.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.4.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.4.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.4.fc1.weight\n",
            "model.decoder.layers.4.fc1.bias\n",
            "model.decoder.layers.4.fc2.weight\n",
            "model.decoder.layers.4.fc2.bias\n",
            "model.decoder.layers.4.final_layer_norm.weight\n",
            "model.decoder.layers.4.final_layer_norm.bias\n",
            "model.decoder.layers.5.self_attn.k_proj.weight\n",
            "model.decoder.layers.5.self_attn.k_proj.bias\n",
            "model.decoder.layers.5.self_attn.v_proj.weight\n",
            "model.decoder.layers.5.self_attn.v_proj.bias\n",
            "model.decoder.layers.5.self_attn.q_proj.weight\n",
            "model.decoder.layers.5.self_attn.q_proj.bias\n",
            "model.decoder.layers.5.self_attn.out_proj.weight\n",
            "model.decoder.layers.5.self_attn.out_proj.bias\n",
            "model.decoder.layers.5.self_attn_layer_norm.weight\n",
            "model.decoder.layers.5.self_attn_layer_norm.bias\n",
            "model.decoder.layers.5.encoder_attn.k_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.k_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.v_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.v_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.q_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.q_proj.bias\n",
            "model.decoder.layers.5.encoder_attn.out_proj.weight\n",
            "model.decoder.layers.5.encoder_attn.out_proj.bias\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.weight\n",
            "model.decoder.layers.5.encoder_attn_layer_norm.bias\n",
            "model.decoder.layers.5.fc1.weight\n",
            "model.decoder.layers.5.fc1.bias\n",
            "model.decoder.layers.5.fc2.weight\n",
            "model.decoder.layers.5.fc2.bias\n",
            "model.decoder.layers.5.final_layer_norm.weight\n",
            "model.decoder.layers.5.final_layer_norm.bias\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "167a381f",
      "metadata": {
        "id": "167a381f"
      },
      "source": [
        "이미 학습된 모델을 통해 추론을 진행합니다.\n",
        "위의 실습에서 추론했던 것과는 다르게 학습된 모델이므로 성능이 더 높게 나타납니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "id": "7f0ec813",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7f0ec813",
        "outputId": "e53cc218-867b-49bf-cb5e-9d56263d1a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SRC: 나는 학교에 간다.\n",
            "MT : I'm going to school.\n"
          ]
        }
      ],
      "source": [
        "text = \"나는 학교에 간다.\"\n",
        "\"\"\"여기서는 batch로 입력을 처리하여 차원이 [seq_len]이 아닌 [batch_size, seq_len]입니다. 여기서는 입력이 한개이므로 [1, seq_len]입니다.\"\"\"\n",
        "encoded = tokenizer(text, return_tensors=\"pt\")\n",
        "\n",
        "generated_ids = model.generate(\n",
        "    **encoded,\n",
        "    max_new_tokens=64,\n",
        ")\n",
        "\n",
        "translation = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(\"SRC:\", text)\n",
        "print(\"MT :\", translation)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0383cf9c",
      "metadata": {
        "id": "0383cf9c"
      },
      "source": [
        "# 5. 아키텍처별 모델 다뤄보기(Encoder model, Decoder model)\n",
        "\n",
        "- 학습 목표\n",
        "  1. huggingface 라이브러리를 이용하여 다양한 모델 구조의 모델을 다룰 수 있다.\n",
        "- 학습 개념\n",
        "  1. huggingface\n",
        "- 학습 내용\n",
        "  1. 문맥을 양방향으로 이해하는 데 강점이 있는 BERT 모델을 사용하여 문장의 빈칸([MASK])에 가장 적절한 단어를 추론\n",
        "  2. 이전 텍스트를 바탕으로 다음 텍스트를 생성하는 데 특화된 GPT-2 모델을 사용하여 이야기의 뒷부분을 창작\n",
        "\n",
        "지금까지는 Seq2Seq(Encoder - Decoder) 모델 구조를 다뤘습니다. 하지만, 현재 가장 많이 사용되는 모델은 Only Decoder 모델입니다.\n",
        "\n",
        "1. Only Encoder 모델 : BERT 같은 모델. RAG등 문서 검색에 주로 사용\n",
        "2. Only Decoder 모델 : Chat-GPT 같은 모델. 대화, 번역, 챗봇 등 현재 가장 많이 사용\n",
        "3. Encoder - Decoder 모델 : 최근에는 잘 사용하지 않음\n",
        "\n",
        "그러면 Only Encoder 모델과 Only Decoder 모델을 이용해 모델 추론을 해보겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8039a153",
      "metadata": {
        "id": "8039a153"
      },
      "source": [
        "Encoder의 대표 모델인 BERT 모델을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "id": "3ddc1fad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ddc1fad",
        "outputId": "cca457ad-104e-498e-d808-c7be03fc9ea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
        "\n",
        "model_name = \"bert-base-cased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForMaskedLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4665108b",
      "metadata": {
        "id": "4665108b"
      },
      "source": [
        "BERT 모델을 이용하여 빈칸 맞추기(Masked Language Modeling)를 추론해봅니다.\n",
        "\n",
        "예를 들어, I [MASK] to school. 이라는 문장에서 [MASK]에 들어갈 단어를 맞춘다고 하면 I go to school. 이 문장이 정답이 됩니다.\n",
        "\n",
        "하지만, I went to school도 정답이 될 수 있습니다.\n",
        "\n",
        "이처럼 [MASK]에 들어갈 단어는 여러가지가 될 수 있고, 모델의 학습에 따라 어떤 단어가 [MASK]에 들어갈지 결정됩니다.\n",
        "\n",
        "이러한 특성을 이용하여 BERT 모델을 이용하여 빈칸 맞추기(`[MASK]`)를 추론해봅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "id": "4ce98fb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ce98fb7",
        "outputId": "a99c2045-9192-45e5-d8a7-f50f021674af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원본 문장: I [MASK] to school.\n",
            "BERT가 예측한 문장들:\n",
            "1순위: I went to school.\n",
            "2순위: I go to school.\n",
            "3순위: I walked to school.\n",
            "4순위: I ran to school.\n",
            "5순위: I got to school.\n"
          ]
        }
      ],
      "source": [
        "# 4. 우리가 맞출 문장 만들기. tokenizer.mask_token = \"[MASK]\" 이 부분이 빈칸이 됨\n",
        "sentence = f\"I {tokenizer.mask_token} to school.\"\n",
        "\n",
        "top_k = 5  # 상위 5개 후보 단어를 보고 싶다\n",
        "\n",
        "# 5. 문장을 숫자로 바꿔서 BERT가 읽을 수 있게 준비\n",
        "encoded = tokenizer(sentence, return_tensors=\"pt\", return_attention_mask=True)\n",
        "\n",
        "# 6. 숫자로 된 문장 정보에서 '입력 토큰 ID' 꺼내기\n",
        "input_ids = encoded.input_ids\n",
        "\n",
        "# 7. [MASK]의 숫자 아이디 가져오기\n",
        "mask_token_id = tokenizer.mask_token_id\n",
        "\n",
        "# 8. 문장에서 [MASK]가 있는 위치(인덱스) 찾기 mask_positions는 (배치 번호, 문장 속 위치) 형태로 저장됨\n",
        "# TODO: 직접 구현해보세요!\n",
        "# mask_positions = FIXME\n",
        "mask_positions = (input_ids == mask_token_id).nonzero(as_tuple=False)\n",
        "# 9. BERT 모델에 문장(숫자형태)을 넣어서 예측 결과(logits) 얻기\n",
        "outputs = model(**encoded)\n",
        "\n",
        "# 10. logits: 각 단어 위치마다 '다음 단어일 가능성'을 모든 단어 사전 크기만큼 기록한 값\n",
        "logits = outputs.logits.squeeze(0)  # (seq_len, vocab_size)\n",
        "\n",
        "# 11. 모든 [MASK] 위치에 대해 예측하기\n",
        "all_token_candidates: List[List[Tuple[str, float]]] = []\n",
        "for _, pos in mask_positions:\n",
        "    pos = pos.item()  # 위치 숫자 꺼내기\n",
        "    logits_at_pos = logits[pos]  # 해당 위치의 예측 점수\n",
        "    probs = torch.softmax(logits_at_pos, dim=-1)  # 점수를 확률로 변환\n",
        "    topk = torch.topk(probs, k=top_k)  # 확률이 높은 상위 5개 선택\n",
        "\n",
        "    ids = topk.indices.tolist()   # 단어 ID\n",
        "    scores = topk.values.tolist() # 확률 값\n",
        "\n",
        "    # 단어 ID를 실제 단어(토큰)로 변환\n",
        "    tokens = [tokenizer.convert_ids_to_tokens(tid) for tid in ids]\n",
        "\n",
        "    # (단어, 확률) 형태로 묶어서 저장\n",
        "    candidates = list(zip(tokens, scores))\n",
        "    all_token_candidates.append(candidates)\n",
        "\n",
        "# 12. [MASK]에 들어갈 단어로 완성된 문장들을 저장할 리스트\n",
        "restored_sentences: List[str] = []\n",
        "\n",
        "# 13. 첫 번째 [MASK] 위치의 후보 단어들\n",
        "token_candidates: List[Tuple[str, float]] = all_token_candidates[0]\n",
        "\n",
        "# 14. 후보 단어들을 하나씩 넣어서 문장을 만들어 보기\n",
        "for tok, _ in token_candidates:\n",
        "    new_ids = input_ids.clone()  # 원래 문장의 숫자 복사\n",
        "    tok_id = tokenizer.convert_tokens_to_ids(tok)  # 후보 단어를 숫자로 변환\n",
        "    new_ids[0, mask_positions[0, 1]] = tok_id      # [MASK] 위치에 후보 단어 ID 넣기\n",
        "    text = tokenizer.decode(new_ids[0], skip_special_tokens=True)  # 다시 글자로 변환\n",
        "    restored_sentences.append(text.strip())  # 앞뒤 공백 제거 후 저장\n",
        "\n",
        "# 15. 결과 출력\n",
        "print(\"원본 문장:\", sentence)\n",
        "print(\"BERT가 예측한 문장들:\")\n",
        "for idx, sent in enumerate(restored_sentences, start=1):\n",
        "    print(\"{}순위: {}\".format(idx, sent))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be9e04c7",
      "metadata": {
        "id": "be9e04c7"
      },
      "source": [
        "Only Decoder 모델의 대표인 GPT 모델을 이용하여 추론을 해보겠습니다.\n",
        "\n",
        "GPT-2 모델을 불러옵니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "id": "6a49ab04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d822331636b54226a90ec8068017591a",
            "bde41ccb8b894792a3444a5000c2bbcf",
            "0d8e728bf97c433b944f521a3085a878",
            "0f422dff010346bab0e3050a4de75dd4",
            "4e0d070d7b604a3e94bd4e3435a4ec7c",
            "87efd8e279dd43a4a23cf6bd6f49f8bf",
            "8a09793258a3462e99ead6cc893ffc8a",
            "8d8573c3699249cea5c9e8ad5548bc43",
            "5297b0cc937e407abab25960ee26a197",
            "d4cc391f928c4ccab7211557d9c012b7",
            "4d1588ac3d524c58ba36351e48e34015",
            "22840c3cc582414a80c6c70ddae052d0",
            "ac7cfce986994590a54f7b8413e0563d",
            "524a7a85b8694d84b3214ef490503952",
            "90725ea3d7594ebf92b1bcfd2cc23800",
            "0e57aed339a545208344f31769b7ee93",
            "cec80e0acf0e4acdb06e6f6f229dd3ab",
            "dafd691956714c57b124fabb07bf7217",
            "60465898284c45f4b9c79159b67c874d",
            "f7e1bff003f94196a17bbf427fabbaaa",
            "f633fa54eba1496eb6c83e1d67155ea7",
            "16f5295da6d74748a5a433682b8bf6a4",
            "4411e375c41c4f129eb57e6a30287318",
            "4d388f1ac672491193026e8caa4c0a75",
            "bb0640cf53ba4f98b120cd1aabf455f4",
            "2131723a974442f38442473f5d0a1481",
            "84658c8d2caa4f67979d1c730074b3a4",
            "1cf02c3f981b46e8b1cacac930cabd10",
            "226e98bc16684d45b3710cfcc9079dc4",
            "a4f884f6f8824d178ef471b70b7d98c9",
            "547a6833d08045c2a28561dadddd4577",
            "b0cc4e718d554450a881eb1c08b59577",
            "f53a6f90251c4a19b9137060fb2f1985",
            "0aea2a55a8e34c10b5c5053527f445ad",
            "e579704990274385b7d2081592ac2f93",
            "44b3a7745f1148768fa2614a71eedce4",
            "799a0e63c04f4a2fb255299a594a253d",
            "b98362945b514c468884f27c2dde1a12",
            "138e58464b5e4210ae67a1e95fa8307c",
            "c631a062003f4ead9d9306ae96ab035e",
            "6abd8429ee3a439abc7d8fda74194ea3",
            "4881c956020048c282002f823e51644d",
            "7c650f54787d45dc9e271437185363ff",
            "25438d5c9cfc43e4934cabc8da33449f",
            "0c12615df2b44cc19d2138c0380226e8",
            "f05b2569f64943c884af515e3b11cc70",
            "aba5c683fa2f492ebb1b9aba05c6ed69",
            "84b35fa5e7cb4693bd6fa0ebdffa3d01",
            "5ea2cfabe20547ea8cc6787317053645",
            "cb9ee21d6c934c4aa5ae829bd71769b4",
            "65f518cc329941dc9b2ecdbce3603e4b",
            "d601b0ef008b4cb89db9e993e666fb8b",
            "d124fd549c10455aa695b9ffe5265f73",
            "8587aaff265a46b5bbb32d063ae4e8b8",
            "b7f3f521f0424f3abc978a4e34f44a0d",
            "d4723b140ae346aa819b3ad69a3c30c9",
            "f7beaf61735b41f5adde2f421f3cccc9",
            "64a8739f7c5649e4bb6a977d055e9233",
            "141080b7520541e88e8b7f07217fa5d9",
            "3bc592cb4e38403eb0b2156532fd0ba1",
            "5b44650f82dd47b2b9de192490dc51fd",
            "325084eea6874d0f982b5769accc8479",
            "8f19a9f72c684445b6fb3fa15268d4c6",
            "41f7240c90ae4805a6e3c46a02966787",
            "7e28d0c84c38416ca441cbc0aac27966",
            "72ec2aed6ade4306a9861bc2cb5d39e0",
            "3c35bd06a28c4f108b492684cef182f2",
            "10e29fb7173d47d6824035431754c5df",
            "63a1fdc1d28e44308020bce85ffd738a",
            "8a9276f053224277906e0748acd47047",
            "eb27aa47cb81448f812ed98887edb216",
            "d8489a57c0ea47b382a765785b4dfdeb",
            "a943724ad27446dba1333d4bb632fdb3",
            "f022a15e255f4fec83006eb2b78d791e",
            "ac70b7e9e4554da5946bb3d79ff7aea5",
            "8e60410e74c34706a0c00bb61fbd2bd0",
            "aefe2bee87fa4309a51d8ef1d53ca188"
          ]
        },
        "id": "6a49ab04",
        "outputId": "75389b12-61ea-4a55-a812-d74f9a5fc962"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d822331636b54226a90ec8068017591a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "22840c3cc582414a80c6c70ddae052d0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4411e375c41c4f129eb57e6a30287318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0aea2a55a8e34c10b5c5053527f445ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0c12615df2b44cc19d2138c0380226e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4723b140ae346aa819b3ad69a3c30c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3c35bd06a28c4f108b492684cef182f2"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0feb32c0",
      "metadata": {
        "id": "0feb32c0"
      },
      "source": [
        "GPT-2 모델은 입력으로 토큰화된 텍스트를 받고, 그 뒤에 올 단어들을 예측(Next token Prediction)하는 것이 목표입니다.\n",
        "\n",
        "아래 코드를 이용하여 스토리(입력 텍스트)의 뒷 내용을 생성해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "id": "33182f00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33182f00",
        "outputId": "f3f55e68-45b8-4f0d-d62b-56be753bee8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Once upon a time in a small village, a curious child found a mysterious key. The child was a boy named Kiyoshi. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice. He was a boy who had been born with a strange, mysterious, and mysterious voice.\n"
          ]
        }
      ],
      "source": [
        "prompt = \"Once upon a time in a small village, a curious child found a mysterious key.\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "with torch.no_grad():\n",
        "    generated_ids = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=64,\n",
        "    )\n",
        "\n",
        "output_tokens = tokenizer.decode(generated_ids.squeeze(), skip_special_tokens=True)\n",
        "print(output_tokens)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "c10",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d822331636b54226a90ec8068017591a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bde41ccb8b894792a3444a5000c2bbcf",
              "IPY_MODEL_0d8e728bf97c433b944f521a3085a878",
              "IPY_MODEL_0f422dff010346bab0e3050a4de75dd4"
            ],
            "layout": "IPY_MODEL_4e0d070d7b604a3e94bd4e3435a4ec7c"
          }
        },
        "bde41ccb8b894792a3444a5000c2bbcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87efd8e279dd43a4a23cf6bd6f49f8bf",
            "placeholder": "​",
            "style": "IPY_MODEL_8a09793258a3462e99ead6cc893ffc8a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "0d8e728bf97c433b944f521a3085a878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d8573c3699249cea5c9e8ad5548bc43",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5297b0cc937e407abab25960ee26a197",
            "value": 26
          }
        },
        "0f422dff010346bab0e3050a4de75dd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4cc391f928c4ccab7211557d9c012b7",
            "placeholder": "​",
            "style": "IPY_MODEL_4d1588ac3d524c58ba36351e48e34015",
            "value": " 26.0/26.0 [00:00&lt;00:00, 230B/s]"
          }
        },
        "4e0d070d7b604a3e94bd4e3435a4ec7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87efd8e279dd43a4a23cf6bd6f49f8bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a09793258a3462e99ead6cc893ffc8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d8573c3699249cea5c9e8ad5548bc43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5297b0cc937e407abab25960ee26a197": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d4cc391f928c4ccab7211557d9c012b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d1588ac3d524c58ba36351e48e34015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "22840c3cc582414a80c6c70ddae052d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac7cfce986994590a54f7b8413e0563d",
              "IPY_MODEL_524a7a85b8694d84b3214ef490503952",
              "IPY_MODEL_90725ea3d7594ebf92b1bcfd2cc23800"
            ],
            "layout": "IPY_MODEL_0e57aed339a545208344f31769b7ee93"
          }
        },
        "ac7cfce986994590a54f7b8413e0563d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cec80e0acf0e4acdb06e6f6f229dd3ab",
            "placeholder": "​",
            "style": "IPY_MODEL_dafd691956714c57b124fabb07bf7217",
            "value": "config.json: 100%"
          }
        },
        "524a7a85b8694d84b3214ef490503952": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60465898284c45f4b9c79159b67c874d",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7e1bff003f94196a17bbf427fabbaaa",
            "value": 665
          }
        },
        "90725ea3d7594ebf92b1bcfd2cc23800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f633fa54eba1496eb6c83e1d67155ea7",
            "placeholder": "​",
            "style": "IPY_MODEL_16f5295da6d74748a5a433682b8bf6a4",
            "value": " 665/665 [00:00&lt;00:00, 6.47kB/s]"
          }
        },
        "0e57aed339a545208344f31769b7ee93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cec80e0acf0e4acdb06e6f6f229dd3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafd691956714c57b124fabb07bf7217": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60465898284c45f4b9c79159b67c874d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7e1bff003f94196a17bbf427fabbaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f633fa54eba1496eb6c83e1d67155ea7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16f5295da6d74748a5a433682b8bf6a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4411e375c41c4f129eb57e6a30287318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d388f1ac672491193026e8caa4c0a75",
              "IPY_MODEL_bb0640cf53ba4f98b120cd1aabf455f4",
              "IPY_MODEL_2131723a974442f38442473f5d0a1481"
            ],
            "layout": "IPY_MODEL_84658c8d2caa4f67979d1c730074b3a4"
          }
        },
        "4d388f1ac672491193026e8caa4c0a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1cf02c3f981b46e8b1cacac930cabd10",
            "placeholder": "​",
            "style": "IPY_MODEL_226e98bc16684d45b3710cfcc9079dc4",
            "value": "vocab.json: 100%"
          }
        },
        "bb0640cf53ba4f98b120cd1aabf455f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a4f884f6f8824d178ef471b70b7d98c9",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_547a6833d08045c2a28561dadddd4577",
            "value": 1042301
          }
        },
        "2131723a974442f38442473f5d0a1481": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0cc4e718d554450a881eb1c08b59577",
            "placeholder": "​",
            "style": "IPY_MODEL_f53a6f90251c4a19b9137060fb2f1985",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 8.48MB/s]"
          }
        },
        "84658c8d2caa4f67979d1c730074b3a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cf02c3f981b46e8b1cacac930cabd10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "226e98bc16684d45b3710cfcc9079dc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a4f884f6f8824d178ef471b70b7d98c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "547a6833d08045c2a28561dadddd4577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b0cc4e718d554450a881eb1c08b59577": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f53a6f90251c4a19b9137060fb2f1985": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0aea2a55a8e34c10b5c5053527f445ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e579704990274385b7d2081592ac2f93",
              "IPY_MODEL_44b3a7745f1148768fa2614a71eedce4",
              "IPY_MODEL_799a0e63c04f4a2fb255299a594a253d"
            ],
            "layout": "IPY_MODEL_b98362945b514c468884f27c2dde1a12"
          }
        },
        "e579704990274385b7d2081592ac2f93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_138e58464b5e4210ae67a1e95fa8307c",
            "placeholder": "​",
            "style": "IPY_MODEL_c631a062003f4ead9d9306ae96ab035e",
            "value": "merges.txt: 100%"
          }
        },
        "44b3a7745f1148768fa2614a71eedce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6abd8429ee3a439abc7d8fda74194ea3",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4881c956020048c282002f823e51644d",
            "value": 456318
          }
        },
        "799a0e63c04f4a2fb255299a594a253d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c650f54787d45dc9e271437185363ff",
            "placeholder": "​",
            "style": "IPY_MODEL_25438d5c9cfc43e4934cabc8da33449f",
            "value": " 456k/456k [00:00&lt;00:00, 5.00MB/s]"
          }
        },
        "b98362945b514c468884f27c2dde1a12": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "138e58464b5e4210ae67a1e95fa8307c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c631a062003f4ead9d9306ae96ab035e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6abd8429ee3a439abc7d8fda74194ea3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4881c956020048c282002f823e51644d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7c650f54787d45dc9e271437185363ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25438d5c9cfc43e4934cabc8da33449f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c12615df2b44cc19d2138c0380226e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f05b2569f64943c884af515e3b11cc70",
              "IPY_MODEL_aba5c683fa2f492ebb1b9aba05c6ed69",
              "IPY_MODEL_84b35fa5e7cb4693bd6fa0ebdffa3d01"
            ],
            "layout": "IPY_MODEL_5ea2cfabe20547ea8cc6787317053645"
          }
        },
        "f05b2569f64943c884af515e3b11cc70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb9ee21d6c934c4aa5ae829bd71769b4",
            "placeholder": "​",
            "style": "IPY_MODEL_65f518cc329941dc9b2ecdbce3603e4b",
            "value": "tokenizer.json: 100%"
          }
        },
        "aba5c683fa2f492ebb1b9aba05c6ed69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d601b0ef008b4cb89db9e993e666fb8b",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d124fd549c10455aa695b9ffe5265f73",
            "value": 1355256
          }
        },
        "84b35fa5e7cb4693bd6fa0ebdffa3d01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8587aaff265a46b5bbb32d063ae4e8b8",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f3f521f0424f3abc978a4e34f44a0d",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 10.1MB/s]"
          }
        },
        "5ea2cfabe20547ea8cc6787317053645": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9ee21d6c934c4aa5ae829bd71769b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f518cc329941dc9b2ecdbce3603e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d601b0ef008b4cb89db9e993e666fb8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d124fd549c10455aa695b9ffe5265f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8587aaff265a46b5bbb32d063ae4e8b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f3f521f0424f3abc978a4e34f44a0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4723b140ae346aa819b3ad69a3c30c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f7beaf61735b41f5adde2f421f3cccc9",
              "IPY_MODEL_64a8739f7c5649e4bb6a977d055e9233",
              "IPY_MODEL_141080b7520541e88e8b7f07217fa5d9"
            ],
            "layout": "IPY_MODEL_3bc592cb4e38403eb0b2156532fd0ba1"
          }
        },
        "f7beaf61735b41f5adde2f421f3cccc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b44650f82dd47b2b9de192490dc51fd",
            "placeholder": "​",
            "style": "IPY_MODEL_325084eea6874d0f982b5769accc8479",
            "value": "model.safetensors: 100%"
          }
        },
        "64a8739f7c5649e4bb6a977d055e9233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f19a9f72c684445b6fb3fa15268d4c6",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41f7240c90ae4805a6e3c46a02966787",
            "value": 548105171
          }
        },
        "141080b7520541e88e8b7f07217fa5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e28d0c84c38416ca441cbc0aac27966",
            "placeholder": "​",
            "style": "IPY_MODEL_72ec2aed6ade4306a9861bc2cb5d39e0",
            "value": " 548M/548M [00:13&lt;00:00, 36.1MB/s]"
          }
        },
        "3bc592cb4e38403eb0b2156532fd0ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b44650f82dd47b2b9de192490dc51fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "325084eea6874d0f982b5769accc8479": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f19a9f72c684445b6fb3fa15268d4c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f7240c90ae4805a6e3c46a02966787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e28d0c84c38416ca441cbc0aac27966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ec2aed6ade4306a9861bc2cb5d39e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c35bd06a28c4f108b492684cef182f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_10e29fb7173d47d6824035431754c5df",
              "IPY_MODEL_63a1fdc1d28e44308020bce85ffd738a",
              "IPY_MODEL_8a9276f053224277906e0748acd47047"
            ],
            "layout": "IPY_MODEL_eb27aa47cb81448f812ed98887edb216"
          }
        },
        "10e29fb7173d47d6824035431754c5df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8489a57c0ea47b382a765785b4dfdeb",
            "placeholder": "​",
            "style": "IPY_MODEL_a943724ad27446dba1333d4bb632fdb3",
            "value": "generation_config.json: 100%"
          }
        },
        "63a1fdc1d28e44308020bce85ffd738a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f022a15e255f4fec83006eb2b78d791e",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac70b7e9e4554da5946bb3d79ff7aea5",
            "value": 124
          }
        },
        "8a9276f053224277906e0748acd47047": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e60410e74c34706a0c00bb61fbd2bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_aefe2bee87fa4309a51d8ef1d53ca188",
            "value": " 124/124 [00:00&lt;00:00, 12.3kB/s]"
          }
        },
        "eb27aa47cb81448f812ed98887edb216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8489a57c0ea47b382a765785b4dfdeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a943724ad27446dba1333d4bb632fdb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f022a15e255f4fec83006eb2b78d791e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac70b7e9e4554da5946bb3d79ff7aea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e60410e74c34706a0c00bb61fbd2bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aefe2bee87fa4309a51d8ef1d53ca188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}